{"cells":[{"cell_type":"markdown","source":["## Attach google drive and install all necessary requirements"],"metadata":{"id":"3C1xC_QFV7x1"}},{"cell_type":"code","source":["!pip install scikit-learn pandas numpy matplotlib seaborn imblearn scipy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IIKJPEUAV7XJ","executionInfo":{"status":"ok","timestamp":1694342933269,"user_tz":-60,"elapsed":4889,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"f4f6003c-c36b-432d-919a-5fb61e1a2687"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n","Collecting imblearn\n","  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.42.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (from imblearn) (0.10.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Installing collected packages: imblearn\n","Successfully installed imblearn-0.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QgPE9VpYUugj","executionInfo":{"status":"ok","timestamp":1694342951069,"user_tz":-60,"elapsed":17807,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"3befc74c-df21-4679-d016-1ada71dda27e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Import all the necessary libraries and datasets"],"metadata":{"id":"bvHePGDBWQ89"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"_Y4FirRKUZgA","executionInfo":{"status":"ok","timestamp":1694343286262,"user_tz":-60,"elapsed":2,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import cross_val_predict\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import cross_val_predict\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve\n","from sklearn.preprocessing import StandardScaler\n","import seaborn as sns\n","import scipy\n","import random\n","import os"]},{"cell_type":"code","source":["data_train = pd.read_csv('/content/drive/MyDrive/sleep onset datasets/data_perfectly_clean_train.csv')\n","data_test = pd.read_csv('/content/drive/MyDrive/sleep onset datasets/data_perfectly_clean_test.csv')\n"],"metadata":{"id":"1jcTwnqgWZ2o","executionInfo":{"status":"ok","timestamp":1694343280315,"user_tz":-60,"elapsed":1586,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["selected_participants_data = pd.read_csv('/content/drive/MyDrive/sleep onset datasets/data_test_perfectly_clean_top_20.csv')\n","selected_participants = selected_participants_data['Sbj_ID'].unique().tolist()\n","selected_participants"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-k9NbDv0WiUw","executionInfo":{"status":"ok","timestamp":1694343280315,"user_tz":-60,"elapsed":5,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"7a5b137c-21bc-46a7-b14e-4bdb2a8d54d3"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[323,\n"," 694,\n"," 912,\n"," 1476,\n"," 2040,\n"," 2651,\n"," 2780,\n"," 3920,\n"," 4014,\n"," 4190,\n"," 4437,\n"," 5749,\n"," 5782,\n"," 5838,\n"," 5876,\n"," 6454,\n"," 10,\n"," 2574,\n"," 5489,\n"," 5881]"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## Define all the helper functions\n"],"metadata":{"id":"v7p1LKs4Waq7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5IQT_u5AUZgC"},"outputs":[],"source":["# Define the device:\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","#Create a PyTorch dataset\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","class SleepDataset(Dataset):\n","    def __init__(self, sequences, labels):\n","        self.sequences = sequences\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        return torch.from_numpy(self.sequences[idx]).float(), torch.from_numpy(np.array(self.labels[idx])).float()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KVS3-OyYUZgC"},"outputs":[],"source":["import numpy as np\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.ensemble import RandomForestRegressor\n","\n","# Create a function to impute the missing values in the dataset\n","def impute_missing_values (dataframe, method = 'LOCF', limit = 20):\n","\n","    # create a missing mask (column) fthat would indicate whether the values in any of the columns of mydata are missing\n","    # 1 indicates missing, 0 indicates not missing\n","    missing_mask = dataframe.isnull().sum(axis=1).astype(bool).astype(int)\n","    dataframe_imputed = dataframe.copy()\n","    dataframe_imputed = pd.concat([dataframe_imputed, missing_mask.rename('ifmissing')], axis=1)\n","\n","    if method == 'LOCF':\n","\n","        dataframe_imputed.fillna(method='ffill', inplace=True, limit = limit)\n","\n","        # fill the rest with backward fill\n","        dataframe_imputed.fillna(method='bfill', inplace=True, limit = limit)\n","\n","    elif method =='NOCB':\n","\n","        dataframe_imputed.fillna(method='bfill', inplace=True, limit = limit)\n","\n","        # fill the rest with forward fill\n","        #dataframe_imputed.fillna(method='ffill', inplace=True, limit = limit)\n","\n","    elif method == 'linear interpolation':\n","\n","        dataframe_imputed.interpolate(method='linear', inplace=True, limit = limit)\n","\n","    elif method == 'quadratic interpolation':\n","\n","        dataframe_imputed.interpolate(method='quadratic', inplace=True, limit = limit)\n","\n","    elif method == 'mean':\n","\n","        dataframe_imputed.fillna(dataframe.mean(), inplace=True, limit = limit)\n","\n","    elif method == 'median':\n","\n","        dataframe_imputed.fillna(dataframe.median(), inplace=True, limit = limit)\n","\n","    elif method == 'MICE':\n","\n","        # Define an imputer\n","        imp = IterativeImputer(estimator=RandomForestRegressor(n_estimators=10, random_state=0),\n","                            missing_values=np.nan,\n","                            sample_posterior=False,\n","                            max_iter=10,\n","                            random_state=0,\n","                            verbose=2)\n","\n","\n","        columns = dataframe_imputed.columns\n","\n","        # Apply the imputer\n","        df_imputed = imp.fit_transform(dataframe_imputed)\n","\n","        # Convert back to DataFrame\n","        dataframe_imputed = pd.DataFrame(df_imputed, columns=columns)\n","\n","    elif method == 'None':\n","        dataframe_imputed = dataframe_imputed\n","\n","    missing_mask_new = dataframe_imputed.isnull().sum(axis=1).astype(bool).astype(int)\n","\n","    dataframe_imputed = pd.concat([dataframe_imputed, missing_mask_new.rename('ifmissing_after_imputation')], axis=1)\n","\n","    return dataframe_imputed\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5rxDLgVQUZgD"},"outputs":[],"source":["\n","\n","# Create a function for creating sliding windows of selected length\n","\n","def create_sliding_windows(data,  window_size_minutes=5,\n","                           ifmissing = True, random_seed = 42, ifoutputsubjects = 0,\n","                           train_proportion = 0.6, ifoutput_end_points = 0,\n","                           resampling_method = None, resampling_proportion = 0.5, iftest = 1):\n","\n","    # Assert whether therea are any NaNs in the data\n","    if not ifmissing:\n","        assert data.isnull().sum().sum() == 0, \"There are NaNs in the data\"\n","\n","    # plot the distribution of labels in the original data\n","    #plt.hist(data['Label'], bins = 60)\n","    #plt.title('Distribution of labels in the original data')\n","    #plt.show()\n","\n","    # check if there are any missing values in the data\n","    #print('Num NaNs in the data:',data.isnull().sum().sum())\n","\n","    # Create a list of all unique subjects\n","    subjects = data['Sbj_ID'].unique()\n","\n","    # Randomly select some of the 80% of subjects to be in the training set, 20% to the validation set and 20% in the test set\n","    np.random.seed(random_seed)\n","\n","\n","    train_subjects = np.random.choice(subjects, size=int(train_proportion*len(subjects)), replace=False)\n","\n","\n","    if iftest == 1:\n","        val_proportions = (1 - train_proportion)/2\n","        val_subjects = np.random.choice(np.setdiff1d(subjects, train_subjects), size=int(val_proportions*len(subjects)), replace=False)\n","        test_subjects = np.setdiff1d(subjects, np.concatenate((train_subjects, val_subjects)))\n","    else:\n","        val_proportions = 1 - train_proportion\n","        val_subjects = np.setdiff1d(subjects, train_subjects)\n","        test_subjects = []\n","\n","\n","\n","    # Print the number of subjects in each set\n","    #print(f'There are {len(train_subjects)} subjects in the training set, {len(val_subjects)} subjects in the validation set and {len(test_subjects)} subjects in the test set')\n","\n","\n","    # Create a new column in the dataframe that indicates whether the subject is in the training set, val set or the test set\n","    data['Set'] = 'train'\n","    data.loc[data['Sbj_ID'].isin(val_subjects), 'Set'] = 'val'\n","    data.loc[data['Sbj_ID'].isin(test_subjects), 'Set'] = 'test'\n","\n","    # Sort your dataframe by Sbj_ID if not already sorted\n","    data = data.sort_values('Sbj_ID')\n","\n","    # Convert the window size from minutes to 6-second epochs\n","    window_size = int((window_size_minutes*60)/6)\n","\n","    # Create empty lists to store your sequences and labels\n","    train_sequences = []\n","    train_labels = []\n","    val_sequences = []\n","    val_labels = []\n","    test_sequences = []\n","    test_labels = []\n","\n","    # Group the DataFrame by subject ID and iterate over each group, dividing into training and test sets\n","    if ifoutput_end_points == 1:\n","        test_end_points = []\n","        test_sleep_stages = []\n","        test_labels = []\n","        val_sleep_stages = []\n","        val_end_points = []\n","    for _, group in data.groupby('Sbj_ID'):\n","\n","        # sort the group by the label in descending order\n","        group = group.sort_values('Label', ascending=False)\n","\n","\n","\n","        # For each group, get the feature columns and convert them into numpy array\n","        if ifoutput_end_points == 1:\n","             group_features = group.drop(['Sbj_ID', 'Label', 'Set', 'ifmissing_after_imputation', 'Old_label', 'ifCleanOnset', 'Time2Sleep', 'SleepStage'], axis=1).to_numpy()\n","             group_old_labels = group['Old_label'].to_numpy()\n","             group_sleep_stages = group['SleepStage'].to_numpy()\n","             group_labels = group['Label'].to_numpy()\n","        else:\n","            group_features = group.drop(['Sbj_ID', 'Label', 'Set', 'ifmissing_after_imputation', 'ifCleanOnset', 'Time2Sleep', 'SleepStage'], axis=1).to_numpy()\n","\n","        ifmissing_column = group['ifmissing_after_imputation'].to_numpy()\n","\n","        train_test = group['Set'].iloc[0]\n","\n","        #if window_size == len(group_features):\n","         #   if train_test == 'train':\n","        #        train_sequences.append(group_features)\n","         #       train_labels.append(group['Label'].iloc[0])\n","         #   elif train_test == 'val':\n","         #       val_sequences.append(group_features)\n","         #       val_labels.append(group['Label'].iloc[0])\n","          #  elif train_test == 'test':\n","         #       test_sequences.append(group_features)\n","          #      test_labels.append(group['Label'].iloc[0])\n","       # elif window_size > len(group_features):\n","        #    continue\n","\n","        # Iterate over the group array with a sliding window\n","        for i in range(len(group_features) - window_size):\n","\n","            # If there are any NaNs in the window, skip it\n","            if ifmissing_column[i : i + window_size].sum() > 0:\n","                continue\n","\n","            if train_test == 'train':\n","\n","                # Append the window data to your sequences\n","                train_sequences.append(group_features[i : i + window_size])\n","\n","                # Append the label corresponding to the end of the window\n","                train_labels.append(group['Label'].iloc[i+window_size])\n","\n","                if ifoutput_end_points == 1:\n","                    # Append the starting point of the window to the list of starting points\n","                    test_end_points.append(group_old_labels[i+window_size])\n","                    test_sleep_stages.append(group_sleep_stages[i+window_size])\n","\n","            elif train_test == 'val':\n","                # Append the window data to your sequences\n","                val_sequences.append(group_features[i : i + window_size])\n","\n","                # Append the label corresponding to the end of the window\n","                val_labels.append(group['Label'].iloc[i+window_size])\n","\n","                if ifoutput_end_points == 1:\n","                    # Append the starting point of the window to the list of starting points\n","                    val_end_points.append(group_old_labels[i+window_size])\n","                    val_sleep_stages.append(group_sleep_stages[i+window_size])\n","\n","\n","            elif train_test == 'test':\n","\n","                # Append the window data to your sequences\n","                test_sequences.append(group_features[i : i + window_size])\n","\n","                # Append the label corresponding to the end of the window\n","                test_labels.append(group['Label'].iloc[i+window_size])\n","\n","\n","    # Convert the sequences and labels into numpy arrays\n","    train_sequences = np.array(train_sequences)\n","    train_labels = np.array(train_labels)\n","\n","\n","\n","    val_sequences = np.array(val_sequences)\n","    val_labels = np.array(val_labels)\n","    test_sequences = np.array(test_sequences)\n","    test_labels = np.array(test_labels)\n","\n","    # plot the distribution of labels in the training set\n","    #plt.hist(train_labels, bins = 60)\n","    #plt.title('Distribution of labels in the training set')\n","    #plt.show()\n","\n","    #if val_labels.size > 0:\n","    #    # plot the distribution of labels in the validation set\n","    #    plt.hist(val_labels, bins = 60)\n","    #    plt.title('Distribution of labels in the validation set')\n","    #    plt.show()\n","\n","    #if test_labels.size > 0:\n","    #    # plot the distribution of labels in the test set\n","    #    plt.hist(test_labels, bins = 60)\n","    #    plt.title('Distribution of labels in the test set')\n","    #    plt.show()\n","\n","\n","    if iftest == 1:\n","        if ifoutputsubjects:\n","            if ifoutput_end_points == 1:\n","                return train_sequences, train_labels, val_sequences, val_labels, test_sequences, test_labels, train_subjects, val_subjects, test_subjects, test_end_points, test_sleep_stages\n","            else:\n","                return train_sequences, train_labels, val_sequences, val_labels, test_sequences, test_labels, train_subjects, val_subjects, test_subjects\n","        else:\n","            if ifoutput_end_points == 1:\n","                return train_sequences, train_labels, val_sequences, val_labels, test_sequences, test_labels, test_end_points, test_sleep_stages\n","            else:\n","                return train_sequences, train_labels, val_sequences, val_labels,  test_sequences, test_labels\n","    else:\n","        if ifoutputsubjects:\n","            if ifoutput_end_points == 1:\n","                return train_sequences, train_labels, val_sequences, val_labels,  train_subjects, val_subjects, val_end_points, val_sleep_stages\n","            else:\n","                return train_sequences, train_labels, val_sequences, val_labels, train_subjects, val_subjects\n","\n","        else:\n","            if ifoutput_end_points == 1:\n","                return train_sequences, train_labels, val_sequences, val_labels, val_end_points, val_sleep_stages\n","            else:\n","                return train_sequences, train_labels, val_sequences, val_labels\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CrAZCnXSUZgD"},"outputs":[],"source":["import torch\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","def train_regression(model, train_loader, num_epochs, criterion,\n","                     optimizer, device, ifplot=False, ifvalidation = True, val_loader = None):\n","\n","    train_losses = []\n","    val_losses = []\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n","\n","        # Train the model\n","        model.train()\n","        running_train_loss = 0.0\n","        train_predictions, train_actuals = [], []\n","        for i, (inputs, labels) in enumerate(train_loader):\n","            inputs = inputs.to(device)\n","            labels= labels.to(device)\n","\n","            # Forward pass\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels.view(-1, 1))\n","\n","            # Backward and optimize\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_train_loss += loss.item()\n","            outputs_detached = outputs.detach()\n","            train_predictions.extend(outputs_detached.cpu().numpy().flatten())\n","            train_actuals.extend(labels.cpu().numpy())\n","\n","        avg_train_loss = running_train_loss / len(train_loader)\n","        train_losses.append(avg_train_loss)\n","\n","\n","\n","        if ifvalidation:\n","            # Validate the model\n","            model.eval()\n","            running_val_loss = 0.0\n","            val_predictions, val_actuals = [], []\n","            with torch.no_grad():\n","                for inputs, labels in val_loader:\n","                    inputs = inputs.to(device)\n","                    labels = labels.to(device)\n","\n","                    outputs = model(inputs)\n","                    running_val_loss += criterion(outputs, labels.view(-1, 1)).item()\n","                    val_predictions.extend(outputs.cpu().numpy().flatten())\n","                    val_actuals.extend(labels.cpu().numpy())\n","\n","\n","\n","                avg_val_loss = running_val_loss / len(val_loader)\n","                val_losses.append(avg_val_loss)\n","\n","        # Calculate metrics\n","        if ifvalidation:\n","            mse = mean_squared_error(val_actuals, val_predictions)\n","            r2 = r2_score(val_actuals, val_predictions)\n","            mae = mean_absolute_error(val_actuals, val_predictions)\n","        else:\n","            mse = mean_squared_error(train_actuals, train_predictions)\n","            r2 = r2_score(train_actuals, train_predictions)\n","            mae = mean_absolute_error(train_actuals, train_predictions)\n","\n","        if ifplot:\n","            print('-'*100)\n","            if ifvalidation:\n","                print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}')\n","            else:\n","                print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss}')\n","            print(f'Mean Squared Error: {mse}, R2 Score: {r2}')\n","            print(f'Mean Absolute Error: {mae}')\n","    if ifvalidation:\n","        del train_predictions, train_actuals\n","        return  val_predictions, val_actuals, train_losses, val_losses, model, optimizer\n","    else:\n","        return  train_predictions, train_actuals, train_losses, model, optimizer\n","\n","\n","# Test function\n","def test_regression(model, test_loader, device, criterion, ifplot=False):\n","    model.eval()\n","    predictions, actuals = [], []\n","\n","    with torch.no_grad():\n","        test_loss = 0\n","        for inputs, labels in test_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)  # these are outputs now\n","            test_loss += criterion(outputs, labels.view(-1, 1)).item()\n","\n","            predictions.extend(outputs.cpu().numpy().flatten())\n","            actuals.extend(labels.cpu().numpy())\n","        if ifplot:\n","            print(f'Test Loss: {test_loss/len(test_loader)}')\n","\n","    # Calculate metrics\n","    mse = mean_squared_error(actuals, predictions)\n","    r2 = r2_score(actuals, predictions)\n","    mae = mean_absolute_error(actuals, predictions)\n","    if ifplot:\n","        print('Mean Squared Error:', mse)\n","        print('R2 Score:', r2)\n","        print('Mean Absolute Error:', mae)\n","    del mse, r2, mae\n","    return predictions, actuals"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"68A7AEhWUZge"},"outputs":[],"source":["def evaluate_regression(predictions, y_test, ifsaveplots = False, savepath = None, ifplot = False, iftest = False, ifperson = False):\n","\n","    # check if the predictions are in the correct format\n","\n","    predictions = np.array(predictions)\n","\n","    # check if the y_test is in the correct format\n","\n","    y_test = np.array(y_test)\n","\n","    errors = abs(y_test - predictions)\n","    mape = np.where(y_test != 0, 100 * (errors / y_test), 0)\n","    accuracy = 100 - np.mean(mape)\n","    mse = sklearn.metrics.mean_squared_error(y_test, predictions)\n","    rmse = np.sqrt(mse)\n","    r2 = sklearn.metrics.r2_score(y_test, predictions)\n","    squared_errors = np.square(y_test - predictions)\n","    weights = 1.0 / (abs(y_test) + 0.1)\n","    custom_mse = np.mean(weights * squared_errors)\n","\n","    if ifplot:\n","\n","        print('Mean Absolute Error:', round(np.mean(errors), 2))\n","        print('Accuracy:', round(accuracy, 2), '%.')\n","        print('Mean Squared Error:', round(mse, 2))\n","        print('Root Mean Squared Error:', round(rmse, 2))\n","        print('R2:', round(r2, 2))\n","        print('Custom MSE:', round(custom_mse, 2))\n","\n","    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=1)\n","    plt.scatter(y_test, predictions, alpha=0.2)\n","    plt.xlabel('Actual time to sleep onset')\n","    plt.ylabel('Predicted time to sleep onset')\n","    plt.title('Actual vs Predicted time to sleep onset')\n","    if ifsaveplots:\n","        if iftest:\n","            plt.savefig(os.path.join(savepath, 'test_actual_vs_predicted.png'))\n","        else:\n","            plt.savefig(os.path.join(savepath, 'crossval_actual_vs_predicted.png'))\n","    if ifplot:\n","        plt.show()\n","    plt.close()\n","\n","    residuals = y_test - predictions\n","    plt.scatter(y_test, residuals, alpha=0.2)\n","    plt.plot([y_test.min(), y_test.max()], [0, 0], 'k--', lw=1)\n","    plt.xlabel('Actual time to sleep onset')\n","    plt.ylabel('Residuals')\n","    plt.title('Actual vs Residuals for predicted time to sleep onset')\n","    if ifsaveplots:\n","        if iftest:\n","            plt.savefig(os.path.join(savepath, 'test_actual_vs_residuals.png'))\n","        else:\n","            plt.savefig(os.path.join(savepath, 'crossval_actual_vs_residuals.png'))\n","    if ifplot:\n","        plt.show()\n","    plt.close()\n","\n","    plt.hist(residuals)\n","    plt.xlabel('Residuals')\n","    plt.ylabel('Frequency')\n","    plt.title('Residuals distribution')\n","    if ifsaveplots:\n","        if iftest:\n","            plt.savefig(os.path.join(savepath, 'test_residuals_distribution.png'))\n","        else:\n","            plt.savefig(os.path.join(savepath, 'crossval_residuals_distribution.png'))\n","    if ifplot:\n","        plt.show()\n","    plt.close()\n","\n","    # for each actual, plot the mean residual\n","    # round y_test to 0.1 decimal place\n","    y_test = np.round(y_test, 1)\n","\n","    predictions_residuals_dict = {}\n","    for i in range(len(y_test)):\n","        if y_test[i] not in predictions_residuals_dict:\n","            predictions_residuals_dict[y_test[i]] = []\n","        predictions_residuals_dict[y_test[i]].append(residuals[i])\n","\n","    # sort it in ascending order of keys\n","    predictions_residuals_dict = dict(sorted(predictions_residuals_dict.items()))\n","\n","\n","    actual_predictions_dict = {}\n","    for i in range(len(y_test)):\n","        if y_test[i] not in actual_predictions_dict:\n","            actual_predictions_dict[y_test[i]] = []\n","        actual_predictions_dict[y_test[i]].append(predictions[i])\n","\n","    # sort it in ascending order of keys\n","    actual_predictions_dict = dict(sorted(actual_predictions_dict.items()))\n","\n","\n","    predictions_residuals_mean_dict = {}\n","    for key in predictions_residuals_dict:\n","        predictions_residuals_mean_dict[key] = np.mean(predictions_residuals_dict[key])\n","\n","    # sort it in ascending order of keys\n","    predictions_residuals_mean_dict = dict(sorted(predictions_residuals_mean_dict.items()))\n","\n","\n","    residuals_std_dict = {}\n","    for key in predictions_residuals_dict:\n","        residuals_std_dict[key] = np.std(predictions_residuals_dict[key])\n","    # sort it in ascending order of keys\n","    residuals_std_dict = dict(sorted(residuals_std_dict.items()))\n","\n","\n","    actuals_predictions_mean_dict = {}\n","    for key in actual_predictions_dict:\n","        actuals_predictions_mean_dict[key] = np.mean(actual_predictions_dict[key])\n","\n","    # sort it in ascending order of keys\n","    actuals_predictions_mean_dict = dict(sorted(actuals_predictions_mean_dict.items()))\n","\n","    predictions_std_dict = {}\n","    for key in actual_predictions_dict:\n","        predictions_std_dict[key] = np.std(actual_predictions_dict[key])\n","    # sort it in ascending order of keys\n","    predictions_std_dict = dict(sorted(predictions_std_dict.items()))\n","\n","    plt.plot(list(predictions_residuals_mean_dict.keys()), list(predictions_residuals_mean_dict.values()))\n","    # create std shading\n","    if not ifperson:\n","        plt.fill_between(list(predictions_residuals_mean_dict.keys()),\n","                        np.array(list(predictions_residuals_mean_dict.values())) - np.array(list(residuals_std_dict.values())),\n","                        np.array(list(predictions_residuals_mean_dict.values())) + np.array(list(residuals_std_dict.values())),\n","                        alpha=0.2)\n","    # plot ideal line (x = 0)\n","\n","\n","    plt.plot([y_test.min(), y_test.max()], [0, 0], 'k--', lw=1, color='red')\n","\n","    plt.xlabel('Actual time to sleep onset')\n","    plt.ylabel('Residuals for this actual')\n","    if ifperson:\n","        plt.legend(['Residuals', 'Ideal residuals line'])\n","        plt.title('Residuals for each actual time to sleep onset')\n","    else:\n","      plt.legend(['Mean of residuals', 'STD of residuals', 'Ideal residuals line'])\n","      plt.title('Mean residual of predictions for each actual time to sleep onset')\n","\n","\n","    if ifsaveplots:\n","        if iftest:\n","            plt.savefig(os.path.join(savepath, 'test_mean_residuals_across_time.png'))\n","        else:\n","            plt.savefig(os.path.join(savepath, 'crossval_mean_residuals_across_time.png'))\n","    if ifplot:\n","        plt.show()\n","    plt.close()\n","\n","    plt.plot(list(actuals_predictions_mean_dict.keys()), list(actuals_predictions_mean_dict.values()))\n","    # create std shading\n","    if not ifperson:\n","        plt.fill_between(list(actuals_predictions_mean_dict.keys()),\n","                          np.array(list(actuals_predictions_mean_dict.values())) - np.array(list(predictions_std_dict.values())),\n","                          np.array(list(actuals_predictions_mean_dict.values())) + np.array(list(predictions_std_dict.values())),\n","                          alpha=0.2)\n","    # plot ideal line (x = y)\n","    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=1, color='red')\n","\n","    plt.xlabel('Actual time to sleep onset')\n","    plt.ylabel('Mean prediction for this actual')\n","\n","    if ifperson:\n","        plt.legend(['Predicted time to sleep','Ideal actual = prediction line (x = y)'])\n","        plt.title('Predicted time for each actual time to sleep onset')\n","    else:\n","        plt.legend(['Mean of predicted time to sleep onset', 'STD of predictions', 'Ideal actual = prediction line (x = y)'])\n","        plt.title('Mean predicted time for each actual time to sleep onset')\n","\n","    if ifsaveplots:\n","        if iftest:\n","            plt.savefig(os.path.join(savepath, 'test_mean_predictions_across_time.png'))\n","        else:\n","             plt.savefig(os.path.join(savepath, 'crossval_mean_predictions_across_time.png'))\n","    if ifplot:\n","        plt.show()\n","    plt.close()\n","\n","    test_metrics = {'MAE': round(np.mean(errors), 2), 'Accuracy': round(accuracy, 2),\n","    'MSE': round(mse, 2), 'RMSE': round(rmse, 2), 'R2': round(r2, 2), 'custom_MSE': round(custom_mse, 2)}\n","\n","\n","    del predictions, predictions_residuals_dict\n","    del actual_predictions_dict, predictions_residuals_mean_dict\n","    del actuals_predictions_mean_dict, predictions_std_dict, residuals, residuals_std_dict, y_test\n","    del mse, rmse, r2, custom_mse\n","\n","    return test_metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PCkA1lFoUZgf"},"outputs":[],"source":["def create_participant_dataloader(data, method, filling_limit, window_size_minutes, random_seed=42):\n","    participant_dataloaders = {}\n","\n","    for sbj in data['Sbj_ID'].unique():\n","\n","        participant_data = data[data['Sbj_ID'] == sbj].copy()\n","\n","        participant_data_imputed = impute_missing_values(participant_data, method=method, limit=filling_limit)\n","        ifmissing = participant_data_imputed.isnull().sum().sum()\n","\n","        test_sequences_sbj, test_targets_sbj, _, _ = create_sliding_windows(\n","            participant_data_imputed,\n","            window_size_minutes=window_size_minutes,\n","            ifmissing=ifmissing,\n","            random_seed=random_seed,\n","            ifoutputsubjects=0,\n","            train_proportion=1,\n","            ifoutput_end_points=0,\n","            resampling_method=None,\n","            resampling_proportion=0.5,\n","            iftest=0\n","        )\n","\n","        # Check if test_sequences_sbj and test_targets_sbj are empty\n","        if len(test_sequences_sbj) == 0 or len(test_targets_sbj) == 0:\n","            print(f\"Skipping participant {sbj} due to lack of data.\")\n","            continue\n","\n","        # Create the test dataset and dataloader with labels and end points (for the regression head)\n","        test_dataset_sbj = SleepDataset(test_sequences_sbj, test_targets_sbj)\n","        test_loader_sbj = DataLoader(test_dataset_sbj, batch_size=1, shuffle=False)\n","\n","        participant_dataloaders[sbj] = test_loader_sbj\n","\n","    return participant_dataloaders\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JC1plvXHUZgf"},"outputs":[],"source":["def test_reg_on_random_participants(participant_dataloaders, model, criterion, device, random_seed, ifplot, output_path_new):\n","\n","    \"\"\"\n","    Test the model on a random subset of participants.\n","    \"\"\"\n","    # Set random seed\n","\n","    # create a new folder for the results\n","    output_path_new = os.path.join(output_path_new, 'random_participants')\n","    if not os.path.exists(output_path_new):\n","        os.makedirs(output_path_new)\n","\n","    # intialise empty dataframe to store results\n","    df_all = pd.DataFrame()\n","\n","\n","    for sbj in list(participant_dataloaders.keys()):\n","        # create a folder for each participant\n","\n","        output_path_participant = os.path.join(output_path_new, str(sbj))\n","        if not os.path.exists(output_path_participant):\n","            os.makedirs(output_path_participant)\n","\n","        test_dataloader = participant_dataloaders[sbj]\n","\n","        predictions, actuals = test_regression(model, test_dataloader, device, criterion)\n","\n","        # get the accuracy of each timepoint\n","        if ifplot:\n","            print('Predict for participant: ', sbj)\n","\n","            print('--------------------------------------Evaluate regression ----------------------------------------')\n","\n","        test_metrics = evaluate_regression(predictions, actuals, iftest=True,\n","                                ifplot=ifplot, savepath =output_path_participant, ifsaveplots= True, ifperson = True)\n","\n","\n","        del test_dataloader, predictions, actuals\n","        df = pd.DataFrame(test_metrics, index = [sbj])\n","        df_all = pd.concat([df_all, df])\n","        del test_metrics\n","\n","    df_all.to_csv(os.path.join(output_path_new, 'regression_results_random_participants.csv'))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7grlm4q8UZgk"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class SleepOnsetRNNRegressor(nn.Module):\n","\n","    def __init__(self, input_size, hidden_size, num_layers, output_size=1, dropout=0.0, l2=0.0):\n","        super(SleepOnsetRNNRegressor, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.l2 = l2\n","\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","\n","        out, _ = self.lstm(x, (h0, c0))\n","        out = self.fc(out[:, -1, :])\n","       #prob = self.sigmoid(out)\n","        return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SUOgkLDHUZgk"},"outputs":[],"source":["def plot_losses(train_losses, test_losses, title, ifplot, ifsaveplots, save_directory, filename, iftest = False):\n","\n","    plt.plot(train_losses, label='Training loss')\n","    if iftest:\n","        plt.plot(test_losses, label='Test loss')\n","    else:\n","      plt.plot(test_losses, label='Validation loss')\n","    plt.title(title)\n","    plt.legend()\n","    if ifplot:\n","        plt.show()\n","    if ifsaveplots:\n","        plt.savefig(os.path.join(save_directory, filename))\n","    plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jw5GIMx8UZgk"},"outputs":[],"source":["def train_and_evaluate_regression_model(model, train_loader, test_loader, criterion, optimizer, device, num_epochs, ifplot, ifsaveplots, output_path):\n","    test_predictions, test_actuals, train_losses, test_losses, model, optimizer = train_regression(\n","        model = model, train_loader = train_loader, val_loader = test_loader, num_epochs = num_epochs, criterion = criterion, optimizer =optimizer, device = device, ifplot = ifplot, ifvalidation = True)\n","\n","    test_metrics = evaluate_regression(test_predictions, test_actuals, ifsaveplots=ifsaveplots, savepath=output_path, ifplot = ifplot)\n","\n","    return train_losses, test_losses, model, optimizer, test_predictions, test_actuals, test_metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ojkPMMlHUZgk"},"outputs":[],"source":["def save_model(model, save_directory, hidden_size, batch_size, window_size_minutes, method):\n","    model_path = os.path.join(save_directory, f'model_h{hidden_size}_b{batch_size}_w{window_size_minutes}_{method}.pt')\n","    torch.save(model.state_dict(), model_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8t0nouXLUZgl"},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","import warnings\n","\n","def training_loop_feature_RNN_regression(mydata, filling_limit, method, input_size, num_epochs, l2, lr, weight_decay, batch_size, device, hidden_size, num_layers,\n","                                        random_seed=42, window_size_minutes=1,  iftest=False, ifoutputpredictions=0,\n","                                        if_stratified_sampling=1, resampling_method=None, ifplot=False, ifresetresults = False,\n","                                        ifsaveplots=True, output_path=None, results_saving_dir = None, loss_function = None, iftrainshuffle = False,\n","                                        selected_participants_data = None, selected_participants = None, test_data =None, pretrained_model = None):\n","\n","    ################## INITIALISATION OF RESULTS STORAGE ##################\n","    warnings.filterwarnings('ignore', category=RuntimeWarning)\n","    warnings.filterwarnings('ignore', category=UserWarning)\n","\n","    if results_saving_dir is None:\n","        results_saving_dir = output_path\n","\n","    save_directory = output_path\n","\n","    if not os.path.exists(save_directory):\n","        os.makedirs(save_directory)\n","\n","    # Initialize a DataFrame to store results\n","    columns = ['hidden_size', 'batch_size', 'sliding_window_size', 'imputation_method',\n","                'MAE', 'MSE', 'RMSE', 'Accuracy', 'R2', 'custom_MSE']\n","\n","    if ifresetresults:\n","        results_df = pd.DataFrame(columns=columns)\n","        results_df.to_csv(os.path.join(results_saving_dir, 'results.csv'))\n","\n","    model_parameters = {'hidden_size': hidden_size,\n","                            'batch_size': batch_size,\n","                            'sliding_window_size': window_size_minutes,\n","                            'imputation_method': method}\n","\n","    ################## PREPROCESS THE DATA: IMPUTATION AND WINDOW CREATION ##################\n","    mydata_imputed = impute_missing_values(mydata, method=method, limit=filling_limit)\n","\n","    if test_data is not None:\n","        test_data_unimputed = test_data.copy()\n","        test_data = impute_missing_values(test_data, method=method, limit=filling_limit)\n","        ifmissing_test = test_data.isnull().sum().sum()\n","\n","    # Check if the dataset still has any missing values\n","    ifmissing = mydata_imputed.isnull().sum().sum()\n","\n","    # Depending on the 'ifprobabilitiesanalysis' flag, process the data differently\n","   # if iftest:\n","    #    train_sequences, train_targets, val_sequences, val_targets, test_sequences, test_targets = create_sliding_windows(mydata_imputed,  window_size_minutes=window_size_minutes,\n","       #                                                                                                             ifmissing = ifmissing, random_seed = 42, ifoutputsubjects = 0,\n","       #                                                                                                             train_proportion = 0.9, ifoutput_end_points = 0,\n","        #                                                                                                            resampling_method = None, resampling_proportion = 0.5, iftest = iftest)\n","   # else:\n","    if iftest and test_data is not None:\n","        if pretrained_model is None:\n","            train_sequences, train_targets, _, _ = create_sliding_windows(mydata_imputed,  window_size_minutes=window_size_minutes,\n","                                                                                                                ifmissing = ifmissing, random_seed = 42, ifoutputsubjects = 0,\n","                                                                                                                    train_proportion = 1.0, ifoutput_end_points = 0,\n","                                                                                                                    resampling_method = None, resampling_proportion = 0.5, iftest = False)\n","        test_sequences, test_targets, _, _ = create_sliding_windows(test_data,  window_size_minutes=window_size_minutes,\n","                                                                 ifmissing = ifmissing_test, random_seed = 42, ifoutputsubjects = 0,\n","                                                                 train_proportion = 1.0, ifoutput_end_points = 0,\n","                                                                 resampling_method = None, resampling_proportion = 0.5, iftest = False)\n","    else:\n","        train_sequences, train_targets, val_sequences, val_targets = create_sliding_windows(mydata_imputed,  window_size_minutes=window_size_minutes,\n","                                                                                                                ifmissing = ifmissing, random_seed = 42, ifoutputsubjects = 0,\n","                                                                                                                    train_proportion = 0.9, ifoutput_end_points = 0,\n","                                                                                                                    resampling_method = None, resampling_proportion = 0.5, iftest = False)\n","\n","    ################### PREPARE LOSS FUNCTION, DATASETS, OPTIMIZER AND MODEL FOR DEEP LEARNING ##################\n","    if loss_function is None:\n","        criterion = nn.MSELoss()\n","    else:\n","        criterion = loss_function\n","\n","    # Create the training, validation, and test datasets\n","    if pretrained_model is None:\n","        train_dataset = SleepDataset(train_sequences, train_targets)\n","         # Create the data loaders\n","        if iftrainshuffle:\n","            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle =True)\n","        else:\n","            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle =False)\n","    if iftest and test_data is not None:\n","        test_dataset = SleepDataset(test_sequences, test_targets)\n","    else:\n","        val_dataset = SleepDataset(val_sequences, val_targets)\n","\n","\n","\n","\n","    if iftest and test_data is not None:\n","        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","        participant_dataloaders = create_participant_dataloader(test_data_unimputed, method, filling_limit, window_size_minutes, random_seed = random_seed)\n","    else:\n","        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","    if selected_participants_data is not None:\n","        participant_dataloaders = create_participant_dataloader(selected_participants_data, method, filling_limit, window_size_minutes, random_seed = random_seed)\n","\n","    # Initialize the model (This model needs to be defined as a regression model)\n","    if pretrained_model is None:\n","        model = SleepOnsetRNNRegressor(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers).to(device)\n","\n","        # Define the optimizer\n","        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n","\n","    ################################# TRAIN THE MODEL  ########################################\n","\n","    if iftest and test_data is not None:\n","        if pretrained_model is None:\n","          train_losses_reg, test_losses_reg, model, optimizer, val_predictions, val_actuals, test_metrics = train_and_evaluate_regression_model(model = model, train_loader =train_loader,\n","                                                                                                                                        test_loader = test_loader, criterion = criterion,\n","                                                                                                                                        optimizer = optimizer, device = device, num_epochs = num_epochs, ifplot = ifplot,\n","                                                                                                                                        ifsaveplots = ifsaveplots, output_path = save_directory)\n","        else:\n","            predictions, actuals = test_regression(model = pretrained_model, test_loader = test_loader, device = device, criterion = criterion, ifplot=False)\n","            test_metrics = evaluate_regression(predictions, actuals, ifsaveplots = ifsaveplots, savepath = save_directory, ifplot = ifplot, iftest = True)\n","    else:\n","        train_losses_reg, test_losses_reg, model, optimizer, val_predictions, val_actuals, test_metrics = train_and_evaluate_regression_model(model = model, train_loader =train_loader,\n","                                                                                                                                        test_loader = val_loader, criterion = criterion,\n","                                                                                                                                    optimizer = optimizer, device = device, num_epochs = num_epochs, ifplot = ifplot,\n","                                                                                                                                        ifsaveplots = ifsaveplots, output_path = save_directory)\n","    if selected_participants is not None:\n","\n","        test_reg_on_random_participants(participant_dataloaders = participant_dataloaders, model = model,  criterion = criterion,\n","                                                device = device, random_seed = random_seed, ifplot = ifplot, output_path_new =save_directory)\n","    if iftest and test_data is not None:\n","        if pretrained_model is None:\n","            test_reg_on_random_participants(participant_dataloaders = participant_dataloaders, model = model,  criterion = criterion,\n","                                                device = device, random_seed = random_seed, ifplot = ifplot, output_path_new =save_directory)\n","        else:\n","            test_reg_on_random_participants(participant_dataloaders = participant_dataloaders, model = pretrained_model,  criterion = criterion,\n","                                                device = device, random_seed = random_seed, ifplot = ifplot, output_path_new =save_directory)\n","\n","\n","\n","    # After each epoch, save the model\n","    if pretrained_model is None:\n","        save_model(model, save_directory, hidden_size, batch_size, window_size_minutes, method)\n","\n","    if pretrained_model is None:\n","      # plot the losses for the regression model\n","      filename = 'regression_losses.png'\n","      if iftest and test_data is not None:\n","        title = 'Training and test losses during regression with window size of ' + str(window_size_minutes) + ' minutes'\n","      else:\n","        title = 'Training and validation losses during regression with window size of ' + str(window_size_minutes) + ' minutes'\n","      plot_losses(train_losses_reg, test_losses_reg, title,\n","                  ifplot, ifsaveplots,\n","                  save_directory = save_directory, filename = filename)\n","\n","\n","    # joing two dictionaries\n","    all_metrics = {**model_parameters, **test_metrics}\n","    # populate the results_df dataframe with the results from the current epoch\n","    new_row = pd.DataFrame(all_metrics, index = [0])\n","    print(new_row)\n","\n","    # Open the results dataframe and add the new results\n","    results_df_all = pd.read_csv(os.path.join(results_saving_dir, 'results.csv'))\n","    results_df_all = pd.concat([results_df_all, new_row], ignore_index=True)\n","    print(results_df_all)\n","\n","    results_df_all.to_csv(os.path.join(results_saving_dir, 'results.csv'), index=False)\n","\n","    del results_df_all\n","    del new_row\n","    del all_metrics\n","\n","    # Clean up the cuda memory\n","    torch.cuda.empty_cache()\n","    # close all the plots\n","    plt.close('all')\n","    # clean up the memory\n","    gc.collect()\n","\n","    #if ifoutputpredictions:\n","    #    return train_losses, val_losses, model, predictions, actuals, mse\n","    # else:\n","    #    return train_losses, val_losses, model\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KpADzjz_UZgl","executionInfo":{"status":"ok","timestamp":1693928941308,"user_tz":-60,"elapsed":423,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"3011a589-8585-424d-eb65-41e51a47834c"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.1099)\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","class CustomMSELoss(nn.Module):\n","    def __init__(self, epsilon=0.1):\n","        super(CustomMSELoss, self).__init__()\n","        self.epsilon = epsilon  # Small value to prevent division by zero\n","\n","    def forward(self, predictions, targets):\n","        # Compute error\n","        errors = (predictions - targets)**2\n","\n","        # Compute weights inversely proportional to target values\n","        weights = 1.0 / (torch.abs(targets) + self.epsilon)\n","\n","        # Weighted sum of errors\n","        loss = torch.sum(weights * errors) / torch.sum(weights)\n","        return loss\n","\n","# Test the custom loss\n","predictions = torch.tensor([0.5, 0.2, 0.7])\n","targets = torch.tensor([0.1, 0.4, 0.8])\n","criterion = CustomMSELoss()\n","loss = criterion(predictions, targets)\n","print(loss)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SXJGSR8GUZgl"},"outputs":[],"source":["import os\n","import gc\n","def hyperparameter_tuning_loop(mydata, hidden_sizes, batch_sizes, window_sizes, imputation_methods,\n","                            results_saving_dir = 'regression_LSTM',  ifresetresults = False,\n","                            selected_participants_data = None, selected_participants = None,\n","                            test_data = None, if_pretrained_model = False, extraction_name = None):\n","\n","    if not os.path.exists(results_saving_dir):\n","        os.makedirs(results_saving_dir)\n","\n","    # Initialize a DataFrame to store results\n","    columns = ['hidden_size', 'batch_size', 'sliding_window_size', 'imputation_method',\n","                'MAE', 'MSE', 'RMSE', 'R2', 'Accuracy', 'custom_MSE']\n","\n","\n","\n","    if ifresetresults:\n","        results_df_all = pd.DataFrame(columns=columns)\n","        results_df_all.to_csv(os.path.join(results_saving_dir, 'results.csv'))\n","\n","\n","\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    for hidden_size in hidden_sizes:\n","        for batch_size in batch_sizes:\n","            for window_size_minutes in window_sizes:\n","                for imputation_method in imputation_methods:\n","                    if imputation_method == 'None':\n","                        method = None\n","                        filling_limit = 0\n","                    else:\n","                        method = imputation_method\n","                        filling_limit = 40\n","\n","\n","                    gc.collect()\n","                    torch.cuda.empty_cache()\n","\n","                    experiment_dir = os.path.join(results_saving_dir, f'hidden_{hidden_size}_batch_{batch_size}_window_{window_size_minutes}_imputation_{imputation_method}')\n","                    if not os.path.exists(experiment_dir):\n","                        os.makedirs(experiment_dir)\n","\n","                    print('Hidden size: ', hidden_size)\n","                    print('Batch_size: ', batch_size)\n","                    print('Window size: ', window_size_minutes)\n","                    print('Imputation method: ', method)\n","\n","                    if test_data is not None:\n","                      iftest = True\n","                    else:\n","                      iftest = False\n","\n","                    if if_pretrained_model:\n","                      pretrained_model = extract_models_from_folder(extraction_name,  hidden_size, batch_size, window_size_minutes, imputation_method)\n","                    else:\n","                      pretrained_model = None\n","\n","                    training_loop_feature_RNN_regression(mydata, filling_limit = filling_limit, method = method, input_size = 86, num_epochs = 30,\n","                                            l2 = 0, lr = 0.001, weight_decay = 0.05, batch_size = batch_size, device = device,\n","                                            hidden_size = hidden_size, num_layers = 2,\n","                                            random_seed=42, window_size_minutes=window_size_minutes,\n","                                            iftest=iftest, ifoutputpredictions=0,\n","                                            if_stratified_sampling=1, resampling_method=None,\n","                                            ifplot=False, ifsaveplots=True, output_path=experiment_dir, results_saving_dir = results_saving_dir,\n","                                            loss_function = CustomMSELoss(), iftrainshuffle = True, ifresetresults = False,\n","                                            selected_participants_data = selected_participants_data, selected_participants = selected_participants,\n","                                            test_data = test_data, pretrained_model = pretrained_model)\n"]},{"cell_type":"markdown","metadata":{"id":"ydMsQWr9UZgl"},"source":["## Hyperparameter tuning"]},{"cell_type":"code","source":["hidden_sizes = [64, 128, 256]\n","batch_sizes = [16, 32, 64]\n","window_sizes = [0.5, 1, 2, 3, 4, 5]\n","imputation_methods = ['None', 'LOCF']"],"metadata":{"id":"l5KKosTbXIIg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["folder_name = '/content/drive/MyDrive/sleep onset datasets/FIXED_regression_LSTM_perfectly_clean_onset'"],"metadata":{"id":"pPkIY_KFXKIk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hyperparameter_tuning_loop(data_train, hidden_sizes, batch_sizes, window_sizes, imputation_methods,\n","                            results_saving_dir = folder_name,  ifresetresults = True,\n","                            selected_participants_data = selected_participants_data, selected_participants = selected_participants)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RS--TuEbXJjw","outputId":"fbe26c5b-a3bf-4a9f-9053-81c910523c0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hidden size:  64\n","Batch_size:  16\n","Window size:  0.5\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          16                  0.5              None  7.09   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     10.35  86.709999  9.31 -0.13        8.01  \n","  Unnamed: 0 hidden_size batch_size  sliding_window_size imputation_method  \\\n","0        NaN          64         16                  0.5              None   \n","\n","    MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0  7.09  86.709999  9.31 -0.13     10.35        8.01  \n","Hidden size:  64\n","Batch_size:  16\n","Window size:  0.5\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          16                  0.5              LOCF  6.71   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      6.69  73.889999   8.6 -0.02        8.53  \n","   Unnamed: 0  hidden_size  batch_size  sliding_window_size imputation_method  \\\n","0         NaN           64          16                  0.5               NaN   \n","1         NaN           64          16                  0.5              LOCF   \n","\n","    MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","Hidden size:  64\n","Batch_size:  16\n","Window size:  1\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          16                    1              None  6.47   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -4.06  70.760002  8.41  0.07        9.49  \n","   Unnamed: 0  hidden_size  batch_size  sliding_window_size imputation_method  \\\n","0         NaN           64          16                  0.5               NaN   \n","1         NaN           64          16                  0.5              LOCF   \n","2         NaN           64          16                  1.0              None   \n","\n","    MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","Hidden size:  64\n","Batch_size:  16\n","Window size:  1\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          16                    1              LOCF  6.71   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      6.95  73.589996  8.58 -0.05        8.34  \n","   Unnamed: 0  hidden_size  batch_size  sliding_window_size imputation_method  \\\n","0         NaN           64          16                  0.5               NaN   \n","1         NaN           64          16                  0.5              LOCF   \n","2         NaN           64          16                  1.0               NaN   \n","3         NaN           64          16                  1.0              LOCF   \n","\n","    MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","Hidden size:  64\n","Batch_size:  16\n","Window size:  2\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method  MAE  \\\n","0           64          16                    2              None  6.2   \n","\n","   Accuracy        MSE  RMSE   R2  custom_MSE  \n","0     -2.97  65.279999  8.08  0.1       10.21  \n","   Unnamed: 0  hidden_size  batch_size  sliding_window_size imputation_method  \\\n","0         NaN           64          16                  0.5               NaN   \n","1         NaN           64          16                  0.5              LOCF   \n","2         NaN           64          16                  1.0               NaN   \n","3         NaN           64          16                  1.0              LOCF   \n","4         NaN           64          16                  2.0              None   \n","\n","    MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","Hidden size:  64\n","Batch_size:  16\n","Window size:  2\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          16                    2              LOCF  6.81   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     20.68  81.230003  9.01 -0.24        6.65  \n","   Unnamed: 0  hidden_size  batch_size  sliding_window_size imputation_method  \\\n","0         NaN           64          16                  0.5               NaN   \n","1         NaN           64          16                  0.5              LOCF   \n","2         NaN           64          16                  1.0               NaN   \n","3         NaN           64          16                  1.0              LOCF   \n","4         NaN           64          16                  2.0               NaN   \n","5         NaN           64          16                  2.0              LOCF   \n","\n","    MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","Hidden size:  64\n","Batch_size:  16\n","Window size:  3\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          16                    3              None  5.55   \n","\n","   Accuracy        MSE  RMSE   R2  custom_MSE  \n","0       5.8  53.349998   7.3  0.2         7.7  \n","   Unnamed: 0  hidden_size  batch_size  sliding_window_size imputation_method  \\\n","0         NaN           64          16                  0.5               NaN   \n","1         NaN           64          16                  0.5              LOCF   \n","2         NaN           64          16                  1.0               NaN   \n","3         NaN           64          16                  1.0              LOCF   \n","4         NaN           64          16                  2.0               NaN   \n","5         NaN           64          16                  2.0              LOCF   \n","6         NaN           64          16                  3.0              None   \n","\n","    MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6  5.55  53.349998  7.30  0.20      5.80        7.70  \n","Hidden size:  64\n","Batch_size:  16\n","Window size:  3\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          16                    3              LOCF  5.79   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     12.13  55.110001  7.42  0.09         7.0  \n","   Unnamed: 0  hidden_size  batch_size  sliding_window_size imputation_method  \\\n","0         NaN           64          16                  0.5               NaN   \n","1         NaN           64          16                  0.5              LOCF   \n","2         NaN           64          16                  1.0               NaN   \n","3         NaN           64          16                  1.0              LOCF   \n","4         NaN           64          16                  2.0               NaN   \n","5         NaN           64          16                  2.0              LOCF   \n","6         NaN           64          16                  3.0               NaN   \n","7         NaN           64          16                  3.0              LOCF   \n","\n","    MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7  5.79  55.110001  7.42  0.09     12.13        7.00  \n","Hidden size:  64\n","Batch_size:  16\n","Window size:  4\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          16                    4              None  5.75   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      7.33  53.889999  7.34  0.16        7.66  \n","   Unnamed: 0  hidden_size  batch_size  sliding_window_size imputation_method  \\\n","0         NaN           64          16                  0.5               NaN   \n","1         NaN           64          16                  0.5              LOCF   \n","2         NaN           64          16                  1.0               NaN   \n","3         NaN           64          16                  1.0              LOCF   \n","4         NaN           64          16                  2.0               NaN   \n","5         NaN           64          16                  2.0              LOCF   \n","6         NaN           64          16                  3.0               NaN   \n","7         NaN           64          16                  3.0              LOCF   \n","8         NaN           64          16                  4.0              None   \n","\n","    MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8  5.75  53.889999  7.34  0.16      7.33        7.66  \n","Hidden size:  64\n","Batch_size:  16\n","Window size:  4\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          16                    4              LOCF  5.91   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      3.45  55.540001  7.45  0.01        8.55  \n","   Unnamed: 0  hidden_size  batch_size  sliding_window_size imputation_method  \\\n","0         NaN           64          16                  0.5               NaN   \n","1         NaN           64          16                  0.5              LOCF   \n","2         NaN           64          16                  1.0               NaN   \n","3         NaN           64          16                  1.0              LOCF   \n","4         NaN           64          16                  2.0               NaN   \n","5         NaN           64          16                  2.0              LOCF   \n","6         NaN           64          16                  3.0               NaN   \n","7         NaN           64          16                  3.0              LOCF   \n","8         NaN           64          16                  4.0               NaN   \n","9         NaN           64          16                  4.0              LOCF   \n","\n","    MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9  5.91  55.540001  7.45  0.01      3.45        8.55  \n","Hidden size:  64\n","Batch_size:  16\n","Window size:  5\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          16                    5              None  4.76   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -4.46  40.860001  6.39  0.33        8.67  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10              None  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","Hidden size:  64\n","Batch_size:  16\n","Window size:  5\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          16                    5              LOCF  5.68   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -8.11  52.810001  7.27 -0.01       10.41  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","Hidden size:  64\n","Batch_size:  32\n","Window size:  0.5\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          32                  0.5              None  6.78   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      4.87  78.330002  8.85 -0.02       10.28  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12              None  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","Hidden size:  64\n","Batch_size:  32\n","Window size:  0.5\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method  MAE  \\\n","0           64          32                  0.5              LOCF  6.6   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -12.42  70.760002  8.41  0.02       12.34  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","Hidden size:  64\n","Batch_size:  32\n","Window size:  1\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method  MAE  \\\n","0           64          32                    1              None  6.7   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -20.93  72.860001  8.54  0.04       11.78  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14              None  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","Hidden size:  64\n","Batch_size:  32\n","Window size:  1\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          32                    1              LOCF  7.01   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      2.32  81.919998  9.05 -0.17         9.4  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","Hidden size:  64\n","Batch_size:  32\n","Window size:  2\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method  MAE  \\\n","0           64          32                    2              None  6.1   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -29.25  64.029999   8.0  0.11       12.08  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16              None  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","Hidden size:  64\n","Batch_size:  32\n","Window size:  2\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          32                    2              LOCF  6.29   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      7.41  64.459999  8.03  0.01        7.79  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","Hidden size:  64\n","Batch_size:  32\n","Window size:  3\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          32                    3              None  5.38   \n","\n","   Accuracy    MSE  RMSE   R2  custom_MSE  \n","0      4.25  46.93  6.85  0.3        6.15  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18              None  5.38  46.930000  6.85  0.30      4.25        6.15  \n","Hidden size:  64\n","Batch_size:  32\n","Window size:  3\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          32                    3              LOCF  5.93   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0      8.51  59.73  7.73  0.02        7.43  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","Hidden size:  64\n","Batch_size:  32\n","Window size:  4\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          32                    4              None  5.92   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      9.23  56.650002  7.53  0.11        6.87  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20              None  5.92  56.650002  7.53  0.11      9.23        6.87  \n","Hidden size:  64\n","Batch_size:  32\n","Window size:  4\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          32                    4              LOCF  6.21   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -14.14  58.830002  7.67 -0.04       10.66  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","Hidden size:  64\n","Batch_size:  32\n","Window size:  5\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          32                    5              None  5.17   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0    -17.56  46.73  6.84  0.23        8.91  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22              None  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","Hidden size:  64\n","Batch_size:  32\n","Window size:  5\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          32                    5              LOCF  5.48   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0     -5.73  50.09  7.08  0.04       10.98  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","Hidden size:  64\n","Batch_size:  64\n","Window size:  0.5\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          64                  0.5              None  7.31   \n","\n","   Accuracy        MSE  RMSE   R2  custom_MSE  \n","0     11.97  91.800003  9.58 -0.2        8.62  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24              None  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","Hidden size:  64\n","Batch_size:  64\n","Window size:  0.5\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method  MAE  \\\n","0           64          64                  0.5              LOCF  7.0   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      6.84  79.300003  8.91 -0.09        8.51  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","Hidden size:  64\n","Batch_size:  64\n","Window size:  1\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          64                    1              None  6.08   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -5.93  64.230003  8.01  0.16        9.61  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26              None  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","Hidden size:  64\n","Batch_size:  64\n","Window size:  1\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          64                    1              LOCF  6.72   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0      3.52  75.75   8.7 -0.08        8.82  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","Hidden size:  64\n","Batch_size:  64\n","Window size:  2\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          64                    2              None  6.19   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0    -29.02  66.07  8.13  0.08        13.1  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28              None  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","Hidden size:  64\n","Batch_size:  64\n","Window size:  2\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          64                    2              LOCF  6.45   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0       6.3  67.190002   8.2 -0.03         8.1  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","Hidden size:  64\n","Batch_size:  64\n","Window size:  3\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          64                    3              None  5.58   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0      12.7  55.43  7.44  0.17        7.35  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30              None  5.58  55.430000  7.44  0.17     12.70        7.35  \n","Hidden size:  64\n","Batch_size:  64\n","Window size:  3\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          64                    3              LOCF  6.14   \n","\n","   Accuracy   MSE  RMSE   R2  custom_MSE  \n","0    -13.16  61.0  7.81 -0.0       11.49  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","Hidden size:  64\n","Batch_size:  64\n","Window size:  4\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          64                    4              None  6.21   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -15.12  63.209999  7.95  0.01       10.32  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32              None  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","Hidden size:  64\n","Batch_size:  64\n","Window size:  4\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n"]}]},{"cell_type":"code","source":["hidden_sizes = [64]\n","batch_sizes = [64]\n","window_sizes = [4, 5]\n","imputation_methods = ['None', 'LOCF']\n","hyperparameter_tuning_loop(data_train, hidden_sizes, batch_sizes, window_sizes, imputation_methods,\n","                            results_saving_dir = folder_name,  ifresetresults = False,\n","                            selected_participants_data = selected_participants_data, selected_participants = selected_participants)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOBsn_zH_42B","executionInfo":{"status":"ok","timestamp":1693492839821,"user_tz":-60,"elapsed":460621,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"ebb8553f-2251-4c5f-8f84-0eca19c20500"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hidden size:  64\n","Batch_size:  64\n","Window size:  4\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          64                    4              None  5.51   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -27.85  53.869999  7.34  0.16       12.62  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33              None  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","Hidden size:  64\n","Batch_size:  64\n","Window size:  4\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          64                    4              LOCF  5.91   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0     12.79  57.23  7.56 -0.02        7.07  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","Hidden size:  64\n","Batch_size:  64\n","Window size:  5\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          64                    5              None  4.98   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -6.27  41.540001  6.45  0.32        7.19  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35              None  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","Hidden size:  64\n","Batch_size:  64\n","Window size:  5\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          64                    5              LOCF  6.07   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -9.36  59.279999   7.7 -0.14        9.73  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n"]}]},{"cell_type":"code","source":["hidden_sizes = [128]\n","batch_sizes = [16, 32, 64]\n","window_sizes = [0.5, 1, 2, 3, 4, 5]\n","imputation_methods = ['None', 'LOCF']\n","hyperparameter_tuning_loop(data_train, hidden_sizes, batch_sizes, window_sizes, imputation_methods,\n","                            results_saving_dir = folder_name,  ifresetresults = False,\n","                            selected_participants_data = selected_participants_data, selected_participants = selected_participants)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"dz7CYXN4__Hz","executionInfo":{"status":"error","timestamp":1693502474176,"user_tz":-60,"elapsed":9634368,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"1d5bf336-09be-475f-b222-1f2b124791b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hidden size:  128\n","Batch_size:  16\n","Window size:  0.5\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          16                  0.5              None  6.71   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -37.99  73.669998  8.58  0.04        17.1  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37              None  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","Hidden size:  128\n","Batch_size:  16\n","Window size:  0.5\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          16                  0.5              LOCF  6.62   \n","\n","   Accuracy    MSE  RMSE   R2  custom_MSE  \n","0     -2.06  72.68  8.53 -0.0       10.03  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","Hidden size:  128\n","Batch_size:  16\n","Window size:  1\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          16                    1              None  6.67   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -11.98  73.400002  8.57  0.04       11.95  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39              None  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","Hidden size:  128\n","Batch_size:  16\n","Window size:  1\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          16                    1              LOCF  6.69   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -8.31  74.290001  8.62 -0.06       11.79  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","Hidden size:  128\n","Batch_size:  16\n","Window size:  2\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method  MAE  \\\n","0          128          16                    2              None  6.7   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -6.95  77.169998  8.78 -0.07        11.3  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41              None  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","Hidden size:  128\n","Batch_size:  16\n","Window size:  2\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          16                    2              LOCF  6.14   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -13.44  61.200001  7.82  0.06       10.78  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","Hidden size:  128\n","Batch_size:  16\n","Window size:  3\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          16                    3              None  5.51   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -4.95  50.439999   7.1  0.25        8.37  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43              None  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","Hidden size:  128\n","Batch_size:  16\n","Window size:  3\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          16                    3              LOCF  5.89   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0    -23.36  51.84   7.2  0.15       10.18  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","44         NaN          128          16                  3.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43               NaN  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","44              LOCF  5.89  51.840000  7.20  0.15    -23.36       10.18  \n","Hidden size:  128\n","Batch_size:  16\n","Window size:  4\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          16                    4              None  5.09   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      8.54  47.009998  6.86  0.27         7.6  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","44         NaN          128          16                  3.0   \n","45         NaN          128          16                  4.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43               NaN  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","44              LOCF  5.89  51.840000  7.20  0.15    -23.36       10.18  \n","45              None  5.09  47.009998  6.86  0.27      8.54        7.60  \n","Hidden size:  128\n","Batch_size:  16\n","Window size:  4\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          16                    4              LOCF  6.11   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -6.44  64.790001  8.05 -0.15       10.19  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","44         NaN          128          16                  3.0   \n","45         NaN          128          16                  4.0   \n","46         NaN          128          16                  4.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43               NaN  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","44              LOCF  5.89  51.840000  7.20  0.15    -23.36       10.18  \n","45               NaN  5.09  47.009998  6.86  0.27      8.54        7.60  \n","46              LOCF  6.11  64.790001  8.05 -0.15     -6.44       10.19  \n","Hidden size:  128\n","Batch_size:  16\n","Window size:  5\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          16                    5              None  4.75   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -3.74  39.779999  6.31  0.34        7.73  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","44         NaN          128          16                  3.0   \n","45         NaN          128          16                  4.0   \n","46         NaN          128          16                  4.0   \n","47         NaN          128          16                  5.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43               NaN  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","44              LOCF  5.89  51.840000  7.20  0.15    -23.36       10.18  \n","45               NaN  5.09  47.009998  6.86  0.27      8.54        7.60  \n","46              LOCF  6.11  64.790001  8.05 -0.15     -6.44       10.19  \n","47              None  4.75  39.779999  6.31  0.34     -3.74        7.73  \n","Hidden size:  128\n","Batch_size:  16\n","Window size:  5\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          16                    5              LOCF  6.06   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0    -15.78  59.18  7.69 -0.14       11.02  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","44         NaN          128          16                  3.0   \n","45         NaN          128          16                  4.0   \n","46         NaN          128          16                  4.0   \n","47         NaN          128          16                  5.0   \n","48         NaN          128          16                  5.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43               NaN  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","44              LOCF  5.89  51.840000  7.20  0.15    -23.36       10.18  \n","45               NaN  5.09  47.009998  6.86  0.27      8.54        7.60  \n","46              LOCF  6.11  64.790001  8.05 -0.15     -6.44       10.19  \n","47               NaN  4.75  39.779999  6.31  0.34     -3.74        7.73  \n","48              LOCF  6.06  59.180000  7.69 -0.14    -15.78       11.02  \n","Hidden size:  128\n","Batch_size:  32\n","Window size:  0.5\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          32                  0.5              None  6.51   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0      4.93  71.57  8.46  0.07        8.82  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","44         NaN          128          16                  3.0   \n","45         NaN          128          16                  4.0   \n","46         NaN          128          16                  4.0   \n","47         NaN          128          16                  5.0   \n","48         NaN          128          16                  5.0   \n","49         NaN          128          32                  0.5   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43               NaN  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","44              LOCF  5.89  51.840000  7.20  0.15    -23.36       10.18  \n","45               NaN  5.09  47.009998  6.86  0.27      8.54        7.60  \n","46              LOCF  6.11  64.790001  8.05 -0.15     -6.44       10.19  \n","47               NaN  4.75  39.779999  6.31  0.34     -3.74        7.73  \n","48              LOCF  6.06  59.180000  7.69 -0.14    -15.78       11.02  \n","49              None  6.51  71.570000  8.46  0.07      4.93        8.82  \n","Hidden size:  128\n","Batch_size:  32\n","Window size:  0.5\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          32                  0.5              LOCF  7.01   \n","\n","   Accuracy   MSE  RMSE   R2  custom_MSE  \n","0     11.13  80.0  8.94 -0.1        7.94  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","44         NaN          128          16                  3.0   \n","45         NaN          128          16                  4.0   \n","46         NaN          128          16                  4.0   \n","47         NaN          128          16                  5.0   \n","48         NaN          128          16                  5.0   \n","49         NaN          128          32                  0.5   \n","50         NaN          128          32                  0.5   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43               NaN  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","44              LOCF  5.89  51.840000  7.20  0.15    -23.36       10.18  \n","45               NaN  5.09  47.009998  6.86  0.27      8.54        7.60  \n","46              LOCF  6.11  64.790001  8.05 -0.15     -6.44       10.19  \n","47               NaN  4.75  39.779999  6.31  0.34     -3.74        7.73  \n","48              LOCF  6.06  59.180000  7.69 -0.14    -15.78       11.02  \n","49               NaN  6.51  71.570000  8.46  0.07      4.93        8.82  \n","50              LOCF  7.01  80.000000  8.94 -0.10     11.13        7.94  \n","Hidden size:  128\n","Batch_size:  32\n","Window size:  1\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          32                    1              None  6.44   \n","\n","   Accuracy        MSE  RMSE   R2  custom_MSE  \n","0      0.07  68.529999  8.28  0.1        9.88  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","44         NaN          128          16                  3.0   \n","45         NaN          128          16                  4.0   \n","46         NaN          128          16                  4.0   \n","47         NaN          128          16                  5.0   \n","48         NaN          128          16                  5.0   \n","49         NaN          128          32                  0.5   \n","50         NaN          128          32                  0.5   \n","51         NaN          128          32                  1.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43               NaN  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","44              LOCF  5.89  51.840000  7.20  0.15    -23.36       10.18  \n","45               NaN  5.09  47.009998  6.86  0.27      8.54        7.60  \n","46              LOCF  6.11  64.790001  8.05 -0.15     -6.44       10.19  \n","47               NaN  4.75  39.779999  6.31  0.34     -3.74        7.73  \n","48              LOCF  6.06  59.180000  7.69 -0.14    -15.78       11.02  \n","49               NaN  6.51  71.570000  8.46  0.07      4.93        8.82  \n","50              LOCF  7.01  80.000000  8.94 -0.10     11.13        7.94  \n","51              None  6.44  68.529999  8.28  0.10      0.07        9.88  \n","Hidden size:  128\n","Batch_size:  32\n","Window size:  1\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method  MAE  \\\n","0          128          32                    1              LOCF  6.7   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      7.88  74.269997  8.62 -0.06        9.28  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","44         NaN          128          16                  3.0   \n","45         NaN          128          16                  4.0   \n","46         NaN          128          16                  4.0   \n","47         NaN          128          16                  5.0   \n","48         NaN          128          16                  5.0   \n","49         NaN          128          32                  0.5   \n","50         NaN          128          32                  0.5   \n","51         NaN          128          32                  1.0   \n","52         NaN          128          32                  1.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43               NaN  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","44              LOCF  5.89  51.840000  7.20  0.15    -23.36       10.18  \n","45               NaN  5.09  47.009998  6.86  0.27      8.54        7.60  \n","46              LOCF  6.11  64.790001  8.05 -0.15     -6.44       10.19  \n","47               NaN  4.75  39.779999  6.31  0.34     -3.74        7.73  \n","48              LOCF  6.06  59.180000  7.69 -0.14    -15.78       11.02  \n","49               NaN  6.51  71.570000  8.46  0.07      4.93        8.82  \n","50              LOCF  7.01  80.000000  8.94 -0.10     11.13        7.94  \n","51               NaN  6.44  68.529999  8.28  0.10      0.07        9.88  \n","52              LOCF  6.70  74.269997  8.62 -0.06      7.88        9.28  \n","Hidden size:  128\n","Batch_size:  32\n","Window size:  2\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          32                    2              None  5.99   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0    -22.08  61.52  7.84  0.15       12.26  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","44         NaN          128          16                  3.0   \n","45         NaN          128          16                  4.0   \n","46         NaN          128          16                  4.0   \n","47         NaN          128          16                  5.0   \n","48         NaN          128          16                  5.0   \n","49         NaN          128          32                  0.5   \n","50         NaN          128          32                  0.5   \n","51         NaN          128          32                  1.0   \n","52         NaN          128          32                  1.0   \n","53         NaN          128          32                  2.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43               NaN  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","44              LOCF  5.89  51.840000  7.20  0.15    -23.36       10.18  \n","45               NaN  5.09  47.009998  6.86  0.27      8.54        7.60  \n","46              LOCF  6.11  64.790001  8.05 -0.15     -6.44       10.19  \n","47               NaN  4.75  39.779999  6.31  0.34     -3.74        7.73  \n","48              LOCF  6.06  59.180000  7.69 -0.14    -15.78       11.02  \n","49               NaN  6.51  71.570000  8.46  0.07      4.93        8.82  \n","50              LOCF  7.01  80.000000  8.94 -0.10     11.13        7.94  \n","51               NaN  6.44  68.529999  8.28  0.10      0.07        9.88  \n","52              LOCF  6.70  74.269997  8.62 -0.06      7.88        9.28  \n","53              None  5.99  61.520000  7.84  0.15    -22.08       12.26  \n","Hidden size:  128\n","Batch_size:  32\n","Window size:  2\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          32                    2              LOCF  6.78   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      9.71  73.790001  8.59 -0.13        8.58  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","44         NaN          128          16                  3.0   \n","45         NaN          128          16                  4.0   \n","46         NaN          128          16                  4.0   \n","47         NaN          128          16                  5.0   \n","48         NaN          128          16                  5.0   \n","49         NaN          128          32                  0.5   \n","50         NaN          128          32                  0.5   \n","51         NaN          128          32                  1.0   \n","52         NaN          128          32                  1.0   \n","53         NaN          128          32                  2.0   \n","54         NaN          128          32                  2.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43               NaN  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","44              LOCF  5.89  51.840000  7.20  0.15    -23.36       10.18  \n","45               NaN  5.09  47.009998  6.86  0.27      8.54        7.60  \n","46              LOCF  6.11  64.790001  8.05 -0.15     -6.44       10.19  \n","47               NaN  4.75  39.779999  6.31  0.34     -3.74        7.73  \n","48              LOCF  6.06  59.180000  7.69 -0.14    -15.78       11.02  \n","49               NaN  6.51  71.570000  8.46  0.07      4.93        8.82  \n","50              LOCF  7.01  80.000000  8.94 -0.10     11.13        7.94  \n","51               NaN  6.44  68.529999  8.28  0.10      0.07        9.88  \n","52              LOCF  6.70  74.269997  8.62 -0.06      7.88        9.28  \n","53               NaN  5.99  61.520000  7.84  0.15    -22.08       12.26  \n","54              LOCF  6.78  73.790001  8.59 -0.13      9.71        8.58  \n","Hidden size:  128\n","Batch_size:  32\n","Window size:  3\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          32                    3              None  5.67   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -9.68  52.599998  7.25  0.22       10.93  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","44         NaN          128          16                  3.0   \n","45         NaN          128          16                  4.0   \n","46         NaN          128          16                  4.0   \n","47         NaN          128          16                  5.0   \n","48         NaN          128          16                  5.0   \n","49         NaN          128          32                  0.5   \n","50         NaN          128          32                  0.5   \n","51         NaN          128          32                  1.0   \n","52         NaN          128          32                  1.0   \n","53         NaN          128          32                  2.0   \n","54         NaN          128          32                  2.0   \n","55         NaN          128          32                  3.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43               NaN  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","44              LOCF  5.89  51.840000  7.20  0.15    -23.36       10.18  \n","45               NaN  5.09  47.009998  6.86  0.27      8.54        7.60  \n","46              LOCF  6.11  64.790001  8.05 -0.15     -6.44       10.19  \n","47               NaN  4.75  39.779999  6.31  0.34     -3.74        7.73  \n","48              LOCF  6.06  59.180000  7.69 -0.14    -15.78       11.02  \n","49               NaN  6.51  71.570000  8.46  0.07      4.93        8.82  \n","50              LOCF  7.01  80.000000  8.94 -0.10     11.13        7.94  \n","51               NaN  6.44  68.529999  8.28  0.10      0.07        9.88  \n","52              LOCF  6.70  74.269997  8.62 -0.06      7.88        9.28  \n","53               NaN  5.99  61.520000  7.84  0.15    -22.08       12.26  \n","54              LOCF  6.78  73.790001  8.59 -0.13      9.71        8.58  \n","55              None  5.67  52.599998  7.25  0.22     -9.68       10.93  \n","Hidden size:  128\n","Batch_size:  32\n","Window size:  3\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          32                    3              LOCF  6.27   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -1.24  64.940002  8.06 -0.07        9.41  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","44         NaN          128          16                  3.0   \n","45         NaN          128          16                  4.0   \n","46         NaN          128          16                  4.0   \n","47         NaN          128          16                  5.0   \n","48         NaN          128          16                  5.0   \n","49         NaN          128          32                  0.5   \n","50         NaN          128          32                  0.5   \n","51         NaN          128          32                  1.0   \n","52         NaN          128          32                  1.0   \n","53         NaN          128          32                  2.0   \n","54         NaN          128          32                  2.0   \n","55         NaN          128          32                  3.0   \n","56         NaN          128          32                  3.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43               NaN  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","44              LOCF  5.89  51.840000  7.20  0.15    -23.36       10.18  \n","45               NaN  5.09  47.009998  6.86  0.27      8.54        7.60  \n","46              LOCF  6.11  64.790001  8.05 -0.15     -6.44       10.19  \n","47               NaN  4.75  39.779999  6.31  0.34     -3.74        7.73  \n","48              LOCF  6.06  59.180000  7.69 -0.14    -15.78       11.02  \n","49               NaN  6.51  71.570000  8.46  0.07      4.93        8.82  \n","50              LOCF  7.01  80.000000  8.94 -0.10     11.13        7.94  \n","51               NaN  6.44  68.529999  8.28  0.10      0.07        9.88  \n","52              LOCF  6.70  74.269997  8.62 -0.06      7.88        9.28  \n","53               NaN  5.99  61.520000  7.84  0.15    -22.08       12.26  \n","54              LOCF  6.78  73.790001  8.59 -0.13      9.71        8.58  \n","55               NaN  5.67  52.599998  7.25  0.22     -9.68       10.93  \n","56              LOCF  6.27  64.940002  8.06 -0.07     -1.24        9.41  \n","Hidden size:  128\n","Batch_size:  32\n","Window size:  4\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          32                    4              None  5.83   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      0.84  54.220001  7.36  0.15         8.1  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","44         NaN          128          16                  3.0   \n","45         NaN          128          16                  4.0   \n","46         NaN          128          16                  4.0   \n","47         NaN          128          16                  5.0   \n","48         NaN          128          16                  5.0   \n","49         NaN          128          32                  0.5   \n","50         NaN          128          32                  0.5   \n","51         NaN          128          32                  1.0   \n","52         NaN          128          32                  1.0   \n","53         NaN          128          32                  2.0   \n","54         NaN          128          32                  2.0   \n","55         NaN          128          32                  3.0   \n","56         NaN          128          32                  3.0   \n","57         NaN          128          32                  4.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43               NaN  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","44              LOCF  5.89  51.840000  7.20  0.15    -23.36       10.18  \n","45               NaN  5.09  47.009998  6.86  0.27      8.54        7.60  \n","46              LOCF  6.11  64.790001  8.05 -0.15     -6.44       10.19  \n","47               NaN  4.75  39.779999  6.31  0.34     -3.74        7.73  \n","48              LOCF  6.06  59.180000  7.69 -0.14    -15.78       11.02  \n","49               NaN  6.51  71.570000  8.46  0.07      4.93        8.82  \n","50              LOCF  7.01  80.000000  8.94 -0.10     11.13        7.94  \n","51               NaN  6.44  68.529999  8.28  0.10      0.07        9.88  \n","52              LOCF  6.70  74.269997  8.62 -0.06      7.88        9.28  \n","53               NaN  5.99  61.520000  7.84  0.15    -22.08       12.26  \n","54              LOCF  6.78  73.790001  8.59 -0.13      9.71        8.58  \n","55               NaN  5.67  52.599998  7.25  0.22     -9.68       10.93  \n","56              LOCF  6.27  64.940002  8.06 -0.07     -1.24        9.41  \n","57              None  5.83  54.220001  7.36  0.15      0.84        8.10  \n","Hidden size:  128\n","Batch_size:  32\n","Window size:  4\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          32                    4              LOCF  6.06   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0      9.84  58.68  7.66 -0.04        7.48  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","44         NaN          128          16                  3.0   \n","45         NaN          128          16                  4.0   \n","46         NaN          128          16                  4.0   \n","47         NaN          128          16                  5.0   \n","48         NaN          128          16                  5.0   \n","49         NaN          128          32                  0.5   \n","50         NaN          128          32                  0.5   \n","51         NaN          128          32                  1.0   \n","52         NaN          128          32                  1.0   \n","53         NaN          128          32                  2.0   \n","54         NaN          128          32                  2.0   \n","55         NaN          128          32                  3.0   \n","56         NaN          128          32                  3.0   \n","57         NaN          128          32                  4.0   \n","58         NaN          128          32                  4.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43               NaN  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","44              LOCF  5.89  51.840000  7.20  0.15    -23.36       10.18  \n","45               NaN  5.09  47.009998  6.86  0.27      8.54        7.60  \n","46              LOCF  6.11  64.790001  8.05 -0.15     -6.44       10.19  \n","47               NaN  4.75  39.779999  6.31  0.34     -3.74        7.73  \n","48              LOCF  6.06  59.180000  7.69 -0.14    -15.78       11.02  \n","49               NaN  6.51  71.570000  8.46  0.07      4.93        8.82  \n","50              LOCF  7.01  80.000000  8.94 -0.10     11.13        7.94  \n","51               NaN  6.44  68.529999  8.28  0.10      0.07        9.88  \n","52              LOCF  6.70  74.269997  8.62 -0.06      7.88        9.28  \n","53               NaN  5.99  61.520000  7.84  0.15    -22.08       12.26  \n","54              LOCF  6.78  73.790001  8.59 -0.13      9.71        8.58  \n","55               NaN  5.67  52.599998  7.25  0.22     -9.68       10.93  \n","56              LOCF  6.27  64.940002  8.06 -0.07     -1.24        9.41  \n","57               NaN  5.83  54.220001  7.36  0.15      0.84        8.10  \n","58              LOCF  6.06  58.680000  7.66 -0.04      9.84        7.48  \n","Hidden size:  128\n","Batch_size:  32\n","Window size:  5\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          32                    5              None  4.38   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      -6.7  33.139999  5.76  0.45        7.65  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","5          NaN           64          16                  2.0   \n","6          NaN           64          16                  3.0   \n","7          NaN           64          16                  3.0   \n","8          NaN           64          16                  4.0   \n","9          NaN           64          16                  4.0   \n","10         NaN           64          16                  5.0   \n","11         NaN           64          16                  5.0   \n","12         NaN           64          32                  0.5   \n","13         NaN           64          32                  0.5   \n","14         NaN           64          32                  1.0   \n","15         NaN           64          32                  1.0   \n","16         NaN           64          32                  2.0   \n","17         NaN           64          32                  2.0   \n","18         NaN           64          32                  3.0   \n","19         NaN           64          32                  3.0   \n","20         NaN           64          32                  4.0   \n","21         NaN           64          32                  4.0   \n","22         NaN           64          32                  5.0   \n","23         NaN           64          32                  5.0   \n","24         NaN           64          64                  0.5   \n","25         NaN           64          64                  0.5   \n","26         NaN           64          64                  1.0   \n","27         NaN           64          64                  1.0   \n","28         NaN           64          64                  2.0   \n","29         NaN           64          64                  2.0   \n","30         NaN           64          64                  3.0   \n","31         NaN           64          64                  3.0   \n","32         NaN           64          64                  4.0   \n","33         NaN           64          64                  4.0   \n","34         NaN           64          64                  4.0   \n","35         NaN           64          64                  5.0   \n","36         NaN           64          64                  5.0   \n","37         NaN          128          16                  0.5   \n","38         NaN          128          16                  0.5   \n","39         NaN          128          16                  1.0   \n","40         NaN          128          16                  1.0   \n","41         NaN          128          16                  2.0   \n","42         NaN          128          16                  2.0   \n","43         NaN          128          16                  3.0   \n","44         NaN          128          16                  3.0   \n","45         NaN          128          16                  4.0   \n","46         NaN          128          16                  4.0   \n","47         NaN          128          16                  5.0   \n","48         NaN          128          16                  5.0   \n","49         NaN          128          32                  0.5   \n","50         NaN          128          32                  0.5   \n","51         NaN          128          32                  1.0   \n","52         NaN          128          32                  1.0   \n","53         NaN          128          32                  2.0   \n","54         NaN          128          32                  2.0   \n","55         NaN          128          32                  3.0   \n","56         NaN          128          32                  3.0   \n","57         NaN          128          32                  4.0   \n","58         NaN          128          32                  4.0   \n","59         NaN          128          32                  5.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","5               LOCF  6.81  81.230003  9.01 -0.24     20.68        6.65  \n","6                NaN  5.55  53.349998  7.30  0.20      5.80        7.70  \n","7               LOCF  5.79  55.110001  7.42  0.09     12.13        7.00  \n","8                NaN  5.75  53.889999  7.34  0.16      7.33        7.66  \n","9               LOCF  5.91  55.540001  7.45  0.01      3.45        8.55  \n","10               NaN  4.76  40.860001  6.39  0.33     -4.46        8.67  \n","11              LOCF  5.68  52.810001  7.27 -0.01     -8.11       10.41  \n","12               NaN  6.78  78.330002  8.85 -0.02      4.87       10.28  \n","13              LOCF  6.60  70.760002  8.41  0.02    -12.42       12.34  \n","14               NaN  6.70  72.860001  8.54  0.04    -20.93       11.78  \n","15              LOCF  7.01  81.919998  9.05 -0.17      2.32        9.40  \n","16               NaN  6.10  64.029999  8.00  0.11    -29.25       12.08  \n","17              LOCF  6.29  64.459999  8.03  0.01      7.41        7.79  \n","18               NaN  5.38  46.930000  6.85  0.30      4.25        6.15  \n","19              LOCF  5.93  59.730000  7.73  0.02      8.51        7.43  \n","20               NaN  5.92  56.650002  7.53  0.11      9.23        6.87  \n","21              LOCF  6.21  58.830002  7.67 -0.04    -14.14       10.66  \n","22               NaN  5.17  46.730000  6.84  0.23    -17.56        8.91  \n","23              LOCF  5.48  50.090000  7.08  0.04     -5.73       10.98  \n","24               NaN  7.31  91.800003  9.58 -0.20     11.97        8.62  \n","25              LOCF  7.00  79.300003  8.91 -0.09      6.84        8.51  \n","26               NaN  6.08  64.230003  8.01  0.16     -5.93        9.61  \n","27              LOCF  6.72  75.750000  8.70 -0.08      3.52        8.82  \n","28               NaN  6.19  66.070000  8.13  0.08    -29.02       13.10  \n","29              LOCF  6.45  67.190002  8.20 -0.03      6.30        8.10  \n","30               NaN  5.58  55.430000  7.44  0.17     12.70        7.35  \n","31              LOCF  6.14  61.000000  7.81 -0.00    -13.16       11.49  \n","32               NaN  6.21  63.209999  7.95  0.01    -15.12       10.32  \n","33               NaN  5.51  53.869999  7.34  0.16    -27.85       12.62  \n","34              LOCF  5.91  57.230000  7.56 -0.02     12.79        7.07  \n","35               NaN  4.98  41.540001  6.45  0.32     -6.27        7.19  \n","36              LOCF  6.07  59.279999  7.70 -0.14     -9.36        9.73  \n","37               NaN  6.71  73.669998  8.58  0.04    -37.99       17.10  \n","38              LOCF  6.62  72.680000  8.53 -0.00     -2.06       10.03  \n","39               NaN  6.67  73.400002  8.57  0.04    -11.98       11.95  \n","40              LOCF  6.69  74.290001  8.62 -0.06     -8.31       11.79  \n","41               NaN  6.70  77.169998  8.78 -0.07     -6.95       11.30  \n","42              LOCF  6.14  61.200001  7.82  0.06    -13.44       10.78  \n","43               NaN  5.51  50.439999  7.10  0.25     -4.95        8.37  \n","44              LOCF  5.89  51.840000  7.20  0.15    -23.36       10.18  \n","45               NaN  5.09  47.009998  6.86  0.27      8.54        7.60  \n","46              LOCF  6.11  64.790001  8.05 -0.15     -6.44       10.19  \n","47               NaN  4.75  39.779999  6.31  0.34     -3.74        7.73  \n","48              LOCF  6.06  59.180000  7.69 -0.14    -15.78       11.02  \n","49               NaN  6.51  71.570000  8.46  0.07      4.93        8.82  \n","50              LOCF  7.01  80.000000  8.94 -0.10     11.13        7.94  \n","51               NaN  6.44  68.529999  8.28  0.10      0.07        9.88  \n","52              LOCF  6.70  74.269997  8.62 -0.06      7.88        9.28  \n","53               NaN  5.99  61.520000  7.84  0.15    -22.08       12.26  \n","54              LOCF  6.78  73.790001  8.59 -0.13      9.71        8.58  \n","55               NaN  5.67  52.599998  7.25  0.22     -9.68       10.93  \n","56              LOCF  6.27  64.940002  8.06 -0.07     -1.24        9.41  \n","57               NaN  5.83  54.220001  7.36  0.15      0.84        8.10  \n","58              LOCF  6.06  58.680000  7.66 -0.04      9.84        7.48  \n","59              None  4.38  33.139999  5.76  0.45     -6.70        7.65  \n","Hidden size:  128\n","Batch_size:  32\n","Window size:  5\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method  MAE  \\\n","0          128          32                    5              LOCF  5.7   \n","\n","   Accuracy    MSE  RMSE   R2  custom_MSE  \n","0    -28.31  51.93  7.21  0.0       11.96  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","56         NaN          128          32                  3.0   \n","57         NaN          128          32                  4.0   \n","58         NaN          128          32                  4.0   \n","59         NaN          128          32                  5.0   \n","60         NaN          128          32                  5.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","56              LOCF  6.27  64.940002  8.06 -0.07     -1.24        9.41  \n","57               NaN  5.83  54.220001  7.36  0.15      0.84        8.10  \n","58              LOCF  6.06  58.680000  7.66 -0.04      9.84        7.48  \n","59               NaN  4.38  33.139999  5.76  0.45     -6.70        7.65  \n","60              LOCF  5.70  51.930000  7.21  0.00    -28.31       11.96  \n","\n","[61 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  64\n","Window size:  0.5\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method  MAE  \\\n","0          128          64                  0.5              None  6.5   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -3.01  71.650002  8.46  0.07       11.92  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","57         NaN          128          32                  4.0   \n","58         NaN          128          32                  4.0   \n","59         NaN          128          32                  5.0   \n","60         NaN          128          32                  5.0   \n","61         NaN          128          64                  0.5   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","57               NaN  5.83  54.220001  7.36  0.15      0.84        8.10  \n","58              LOCF  6.06  58.680000  7.66 -0.04      9.84        7.48  \n","59               NaN  4.38  33.139999  5.76  0.45     -6.70        7.65  \n","60              LOCF  5.70  51.930000  7.21  0.00    -28.31       11.96  \n","61              None  6.50  71.650002  8.46  0.07     -3.01       11.92  \n","\n","[62 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  64\n","Window size:  0.5\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          64                  0.5              LOCF  7.35   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      8.17  87.959999  9.38 -0.21        10.3  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","58         NaN          128          32                  4.0   \n","59         NaN          128          32                  5.0   \n","60         NaN          128          32                  5.0   \n","61         NaN          128          64                  0.5   \n","62         NaN          128          64                  0.5   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","58              LOCF  6.06  58.680000  7.66 -0.04      9.84        7.48  \n","59               NaN  4.38  33.139999  5.76  0.45     -6.70        7.65  \n","60              LOCF  5.70  51.930000  7.21  0.00    -28.31       11.96  \n","61               NaN  6.50  71.650002  8.46  0.07     -3.01       11.92  \n","62              LOCF  7.35  87.959999  9.38 -0.21      8.17       10.30  \n","\n","[63 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  64\n","Window size:  1\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method  MAE  \\\n","0          128          64                    1              None  6.4   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -20.17  71.059998  8.43  0.07       12.27  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","59         NaN          128          32                  5.0   \n","60         NaN          128          32                  5.0   \n","61         NaN          128          64                  0.5   \n","62         NaN          128          64                  0.5   \n","63         NaN          128          64                  1.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","59               NaN  4.38  33.139999  5.76  0.45     -6.70        7.65  \n","60              LOCF  5.70  51.930000  7.21  0.00    -28.31       11.96  \n","61               NaN  6.50  71.650002  8.46  0.07     -3.01       11.92  \n","62              LOCF  7.35  87.959999  9.38 -0.21      8.17       10.30  \n","63              None  6.40  71.059998  8.43  0.07    -20.17       12.27  \n","\n","[64 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  64\n","Window size:  1\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          64                    1              LOCF  6.73   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -15.06  72.389999  8.51 -0.03       11.59  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","60         NaN          128          32                  5.0   \n","61         NaN          128          64                  0.5   \n","62         NaN          128          64                  0.5   \n","63         NaN          128          64                  1.0   \n","64         NaN          128          64                  1.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","60              LOCF  5.70  51.930000  7.21  0.00    -28.31       11.96  \n","61               NaN  6.50  71.650002  8.46  0.07     -3.01       11.92  \n","62              LOCF  7.35  87.959999  9.38 -0.21      8.17       10.30  \n","63               NaN  6.40  71.059998  8.43  0.07    -20.17       12.27  \n","64              LOCF  6.73  72.389999  8.51 -0.03    -15.06       11.59  \n","\n","[65 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  64\n","Window size:  2\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          64                    2              None  6.05   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -2.84  62.450001   7.9  0.13        8.63  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","61         NaN          128          64                  0.5   \n","62         NaN          128          64                  0.5   \n","63         NaN          128          64                  1.0   \n","64         NaN          128          64                  1.0   \n","65         NaN          128          64                  2.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","61               NaN  6.50  71.650002  8.46  0.07     -3.01       11.92  \n","62              LOCF  7.35  87.959999  9.38 -0.21      8.17       10.30  \n","63               NaN  6.40  71.059998  8.43  0.07    -20.17       12.27  \n","64              LOCF  6.73  72.389999  8.51 -0.03    -15.06       11.59  \n","65              None  6.05  62.450001  7.90  0.13     -2.84        8.63  \n","\n","[66 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  64\n","Window size:  2\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          64                    2              LOCF  6.35   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      8.36  68.650002  8.29 -0.05        9.04  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","62         NaN          128          64                  0.5   \n","63         NaN          128          64                  1.0   \n","64         NaN          128          64                  1.0   \n","65         NaN          128          64                  2.0   \n","66         NaN          128          64                  2.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","62              LOCF  7.35  87.959999  9.38 -0.21      8.17       10.30  \n","63               NaN  6.40  71.059998  8.43  0.07    -20.17       12.27  \n","64              LOCF  6.73  72.389999  8.51 -0.03    -15.06       11.59  \n","65               NaN  6.05  62.450001  7.90  0.13     -2.84        8.63  \n","66              LOCF  6.35  68.650002  8.29 -0.05      8.36        9.04  \n","\n","[67 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  64\n","Window size:  3\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          64                    3              None  6.46   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -53.31  66.610001  8.16  0.01       17.93  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","63         NaN          128          64                  1.0   \n","64         NaN          128          64                  1.0   \n","65         NaN          128          64                  2.0   \n","66         NaN          128          64                  2.0   \n","67         NaN          128          64                  3.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","63               NaN  6.40  71.059998  8.43  0.07    -20.17       12.27  \n","64              LOCF  6.73  72.389999  8.51 -0.03    -15.06       11.59  \n","65               NaN  6.05  62.450001  7.90  0.13     -2.84        8.63  \n","66              LOCF  6.35  68.650002  8.29 -0.05      8.36        9.04  \n","67              None  6.46  66.610001  8.16  0.01    -53.31       17.93  \n","\n","[68 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  64\n","Window size:  3\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          64                    3              LOCF  6.38   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -14.53  65.589996   8.1 -0.08       11.45  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","64         NaN          128          64                  1.0   \n","65         NaN          128          64                  2.0   \n","66         NaN          128          64                  2.0   \n","67         NaN          128          64                  3.0   \n","68         NaN          128          64                  3.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","64              LOCF  6.73  72.389999  8.51 -0.03    -15.06       11.59  \n","65               NaN  6.05  62.450001  7.90  0.13     -2.84        8.63  \n","66              LOCF  6.35  68.650002  8.29 -0.05      8.36        9.04  \n","67               NaN  6.46  66.610001  8.16  0.01    -53.31       17.93  \n","68              LOCF  6.38  65.589996  8.10 -0.08    -14.53       11.45  \n","\n","[69 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  64\n","Window size:  4\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          64                    4              None  5.53   \n","\n","   Accuracy    MSE  RMSE   R2  custom_MSE  \n","0      4.45  50.98  7.14  0.2        7.74  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","65         NaN          128          64                  2.0   \n","66         NaN          128          64                  2.0   \n","67         NaN          128          64                  3.0   \n","68         NaN          128          64                  3.0   \n","69         NaN          128          64                  4.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","65               NaN  6.05  62.450001  7.90  0.13     -2.84        8.63  \n","66              LOCF  6.35  68.650002  8.29 -0.05      8.36        9.04  \n","67               NaN  6.46  66.610001  8.16  0.01    -53.31       17.93  \n","68              LOCF  6.38  65.589996  8.10 -0.08    -14.53       11.45  \n","69              None  5.53  50.980000  7.14  0.20      4.45        7.74  \n","\n","[70 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  64\n","Window size:  4\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-35010c8446bc>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwindow_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimputation_methods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'None'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LOCF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m hyperparameter_tuning_loop(data_train, hidden_sizes, batch_sizes, window_sizes, imputation_methods,\n\u001b[0m\u001b[1;32m      6\u001b[0m                             \u001b[0mresults_saving_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder_name\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mifresetresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                             selected_participants_data = selected_participants_data, selected_participants = selected_participants)\n","\u001b[0;32m<ipython-input-20-c76d3b160f87>\u001b[0m in \u001b[0;36mhyperparameter_tuning_loop\u001b[0;34m(mydata, hidden_sizes, batch_sizes, window_sizes, imputation_methods, results_saving_dir, ifresetresults, selected_participants_data, selected_participants)\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Imputation method: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     training_loop_feature_RNN_regression(mydata, filling_limit = filling_limit, method = method, input_size = 86, num_epochs = 30,\n\u001b[0m\u001b[1;32m     48\u001b[0m                                             \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                                             \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-abc5bf8337c7>\u001b[0m in \u001b[0;36mtraining_loop_feature_RNN_regression\u001b[0;34m(mydata, filling_limit, method, input_size, num_epochs, l2, lr, weight_decay, batch_size, device, hidden_size, num_layers, random_seed, window_size_minutes, iftest, ifoutputpredictions, if_stratified_sampling, resampling_method, ifplot, ifresetresults, ifsaveplots, output_path, results_saving_dir, loss_function, iftrainshuffle, selected_participants_data, selected_participants)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m################################# TRAIN THE MODEL  ########################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     train_losses_reg, test_losses_reg, model, optimizer, val_predictions, val_actuals, test_metrics = train_and_evaluate_regression_model(model = model, train_loader =train_loader, \n\u001b[0m\u001b[1;32m     86\u001b[0m                                                                                                                                         \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                                                                                                                                         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mifplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifplot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-99cfd30f59b0>\u001b[0m in \u001b[0;36mtrain_and_evaluate_regression_model\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, device, num_epochs, ifplot, ifsaveplots, output_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_and_evaluate_regression_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mifplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mifsaveplots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     test_predictions, test_actuals, train_losses, test_losses, model, optimizer = train_regression(\n\u001b[0m\u001b[1;32m      3\u001b[0m         model = model, train_loader = train_loader, val_loader = test_loader, num_epochs = num_epochs, criterion = criterion, optimizer =optimizer, device = device, ifplot = ifplot, ifvalidation = True)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtest_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_actuals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mifsaveplots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mifsaveplots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mifplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-088cb10cdebb>\u001b[0m in \u001b[0;36mtrain_regression\u001b[0;34m(model, train_loader, num_epochs, criterion, optimizer, device, ifplot, ifvalidation, val_loader)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["hidden_sizes = [128]\n","batch_sizes = [64]\n","window_sizes = [4, 5]\n","imputation_methods = ['None', 'LOCF']\n","hyperparameter_tuning_loop(data_train, hidden_sizes, batch_sizes, window_sizes, imputation_methods,\n","                            results_saving_dir = folder_name,  ifresetresults = False,\n","                            selected_participants_data = selected_participants_data, selected_participants = selected_participants)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O50uEHTfnU2j","executionInfo":{"status":"ok","timestamp":1693502978207,"user_tz":-60,"elapsed":440145,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"db799462-ae20-4234-9b6d-8f5956cf5233"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hidden size:  128\n","Batch_size:  64\n","Window size:  4\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          64                    4              None  5.44   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0       3.1  48.990002   7.0  0.23        7.43  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","66         NaN          128          64                  2.0   \n","67         NaN          128          64                  3.0   \n","68         NaN          128          64                  3.0   \n","69         NaN          128          64                  4.0   \n","70         NaN          128          64                  4.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","66              LOCF  6.35  68.650002  8.29 -0.05      8.36        9.04  \n","67               NaN  6.46  66.610001  8.16  0.01    -53.31       17.93  \n","68              LOCF  6.38  65.589996  8.10 -0.08    -14.53       11.45  \n","69               NaN  5.53  50.980000  7.14  0.20      4.45        7.74  \n","70              None  5.44  48.990002  7.00  0.23      3.10        7.43  \n","\n","[71 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  64\n","Window size:  4\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          64                    4              LOCF  6.28   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0     -15.1  63.68  7.98 -0.13       10.92  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","67         NaN          128          64                  3.0   \n","68         NaN          128          64                  3.0   \n","69         NaN          128          64                  4.0   \n","70         NaN          128          64                  4.0   \n","71         NaN          128          64                  4.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","67               NaN  6.46  66.610001  8.16  0.01    -53.31       17.93  \n","68              LOCF  6.38  65.589996  8.10 -0.08    -14.53       11.45  \n","69               NaN  5.53  50.980000  7.14  0.20      4.45        7.74  \n","70               NaN  5.44  48.990002  7.00  0.23      3.10        7.43  \n","71              LOCF  6.28  63.680000  7.98 -0.13    -15.10       10.92  \n","\n","[72 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  64\n","Window size:  5\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method  MAE  \\\n","0          128          64                    5              None  5.4   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0     -6.94  46.02  6.78  0.24         7.2  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","68         NaN          128          64                  3.0   \n","69         NaN          128          64                  4.0   \n","70         NaN          128          64                  4.0   \n","71         NaN          128          64                  4.0   \n","72         NaN          128          64                  5.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","68              LOCF  6.38  65.589996  8.10 -0.08    -14.53       11.45  \n","69               NaN  5.53  50.980000  7.14  0.20      4.45        7.74  \n","70               NaN  5.44  48.990002  7.00  0.23      3.10        7.43  \n","71              LOCF  6.28  63.680000  7.98 -0.13    -15.10       10.92  \n","72              None  5.40  46.020000  6.78  0.24     -6.94        7.20  \n","\n","[73 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  64\n","Window size:  5\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          64                    5              LOCF  5.61   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0     -8.83  49.73  7.05  0.05        9.19  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","69         NaN          128          64                  4.0   \n","70         NaN          128          64                  4.0   \n","71         NaN          128          64                  4.0   \n","72         NaN          128          64                  5.0   \n","73         NaN          128          64                  5.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","69               NaN  5.53  50.980000  7.14  0.20      4.45        7.74  \n","70               NaN  5.44  48.990002  7.00  0.23      3.10        7.43  \n","71              LOCF  6.28  63.680000  7.98 -0.13    -15.10       10.92  \n","72               NaN  5.40  46.020000  6.78  0.24     -6.94        7.20  \n","73              LOCF  5.61  49.730000  7.05  0.05     -8.83        9.19  \n","\n","[74 rows x 11 columns]\n"]}]},{"cell_type":"code","source":["hidden_sizes = [64, 128]\n","batch_sizes = [16, 32, 64]\n","window_sizes = [6, 7, 8]\n","imputation_methods = ['LOCF']\n","hyperparameter_tuning_loop(data_train, hidden_sizes, batch_sizes, window_sizes, imputation_methods,\n","                            results_saving_dir = folder_name,  ifresetresults = False,\n","                            selected_participants_data = selected_participants_data, selected_participants = selected_participants)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qfXhf_T-p9-r","executionInfo":{"status":"ok","timestamp":1693507497986,"user_tz":-60,"elapsed":4162873,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"aa3cc7c2-b3ec-4b2d-ac64-d2b66207247e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hidden size:  64\n","Batch_size:  16\n","Window size:  6\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          16                    6              LOCF  5.59   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      2.53  51.849998   7.2 -0.08        6.98  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","70         NaN          128          64                  4.0   \n","71         NaN          128          64                  4.0   \n","72         NaN          128          64                  5.0   \n","73         NaN          128          64                  5.0   \n","74         NaN           64          16                  6.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","70               NaN  5.44  48.990002  7.00  0.23      3.10        7.43  \n","71              LOCF  6.28  63.680000  7.98 -0.13    -15.10       10.92  \n","72               NaN  5.40  46.020000  6.78  0.24     -6.94        7.20  \n","73              LOCF  5.61  49.730000  7.05  0.05     -8.83        9.19  \n","74              LOCF  5.59  51.849998  7.20 -0.08      2.53        6.98  \n","\n","[75 rows x 11 columns]\n","Hidden size:  64\n","Batch_size:  16\n","Window size:  7\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          16                    7              LOCF  5.37   \n","\n","   Accuracy        MSE  RMSE   R2  custom_MSE  \n","0    -21.47  44.130001  6.64 -0.0        9.46  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","71         NaN          128          64                  4.0   \n","72         NaN          128          64                  5.0   \n","73         NaN          128          64                  5.0   \n","74         NaN           64          16                  6.0   \n","75         NaN           64          16                  7.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","71              LOCF  6.28  63.680000  7.98 -0.13    -15.10       10.92  \n","72               NaN  5.40  46.020000  6.78  0.24     -6.94        7.20  \n","73              LOCF  5.61  49.730000  7.05  0.05     -8.83        9.19  \n","74              LOCF  5.59  51.849998  7.20 -0.08      2.53        6.98  \n","75              LOCF  5.37  44.130001  6.64 -0.00    -21.47        9.46  \n","\n","[76 rows x 11 columns]\n","Hidden size:  64\n","Batch_size:  16\n","Window size:  8\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          16                    8              LOCF  4.91   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -26.82  38.689999  6.22  0.04        9.86  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","72         NaN          128          64                  5.0   \n","73         NaN          128          64                  5.0   \n","74         NaN           64          16                  6.0   \n","75         NaN           64          16                  7.0   \n","76         NaN           64          16                  8.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","72               NaN  5.40  46.020000  6.78  0.24     -6.94        7.20  \n","73              LOCF  5.61  49.730000  7.05  0.05     -8.83        9.19  \n","74              LOCF  5.59  51.849998  7.20 -0.08      2.53        6.98  \n","75              LOCF  5.37  44.130001  6.64 -0.00    -21.47        9.46  \n","76              LOCF  4.91  38.689999  6.22  0.04    -26.82        9.86  \n","\n","[77 rows x 11 columns]\n","Hidden size:  64\n","Batch_size:  32\n","Window size:  6\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          32                    6              LOCF  5.41   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0     -11.9  46.66  6.83  0.03        9.35  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","73         NaN          128          64                  5.0   \n","74         NaN           64          16                  6.0   \n","75         NaN           64          16                  7.0   \n","76         NaN           64          16                  8.0   \n","77         NaN           64          32                  6.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","73              LOCF  5.61  49.730000  7.05  0.05     -8.83        9.19  \n","74              LOCF  5.59  51.849998  7.20 -0.08      2.53        6.98  \n","75              LOCF  5.37  44.130001  6.64 -0.00    -21.47        9.46  \n","76              LOCF  4.91  38.689999  6.22  0.04    -26.82        9.86  \n","77              LOCF  5.41  46.660000  6.83  0.03    -11.90        9.35  \n","\n","[78 rows x 11 columns]\n","Hidden size:  64\n","Batch_size:  32\n","Window size:  7\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          32                    7              LOCF  5.41   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -33.3  46.799999  6.84 -0.06        10.8  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","74         NaN           64          16                  6.0   \n","75         NaN           64          16                  7.0   \n","76         NaN           64          16                  8.0   \n","77         NaN           64          32                  6.0   \n","78         NaN           64          32                  7.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","74              LOCF  5.59  51.849998  7.20 -0.08      2.53        6.98  \n","75              LOCF  5.37  44.130001  6.64 -0.00    -21.47        9.46  \n","76              LOCF  4.91  38.689999  6.22  0.04    -26.82        9.86  \n","77              LOCF  5.41  46.660000  6.83  0.03    -11.90        9.35  \n","78              LOCF  5.41  46.799999  6.84 -0.06    -33.30       10.80  \n","\n","[79 rows x 11 columns]\n","Hidden size:  64\n","Batch_size:  32\n","Window size:  8\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          32                    8              LOCF  5.48   \n","\n","   Accuracy        MSE  RMSE   R2  custom_MSE  \n","0    -40.19  48.419998  6.96 -0.2       13.56  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","75         NaN           64          16                  7.0   \n","76         NaN           64          16                  8.0   \n","77         NaN           64          32                  6.0   \n","78         NaN           64          32                  7.0   \n","79         NaN           64          32                  8.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","75              LOCF  5.37  44.130001  6.64 -0.00    -21.47        9.46  \n","76              LOCF  4.91  38.689999  6.22  0.04    -26.82        9.86  \n","77              LOCF  5.41  46.660000  6.83  0.03    -11.90        9.35  \n","78              LOCF  5.41  46.799999  6.84 -0.06    -33.30       10.80  \n","79              LOCF  5.48  48.419998  6.96 -0.20    -40.19       13.56  \n","\n","[80 rows x 11 columns]\n","Hidden size:  64\n","Batch_size:  64\n","Window size:  6\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method  MAE  \\\n","0           64          64                    6              LOCF  5.6   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -18.4  49.490002  7.04 -0.03        9.61  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","76         NaN           64          16                  8.0   \n","77         NaN           64          32                  6.0   \n","78         NaN           64          32                  7.0   \n","79         NaN           64          32                  8.0   \n","80         NaN           64          64                  6.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","76              LOCF  4.91  38.689999  6.22  0.04    -26.82        9.86  \n","77              LOCF  5.41  46.660000  6.83  0.03    -11.90        9.35  \n","78              LOCF  5.41  46.799999  6.84 -0.06    -33.30       10.80  \n","79              LOCF  5.48  48.419998  6.96 -0.20    -40.19       13.56  \n","80              LOCF  5.60  49.490002  7.04 -0.03    -18.40        9.61  \n","\n","[81 rows x 11 columns]\n","Hidden size:  64\n","Batch_size:  64\n","Window size:  7\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          64                    7              LOCF  5.97   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -41.04  55.810001  7.47 -0.27       12.64  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","77         NaN           64          32                  6.0   \n","78         NaN           64          32                  7.0   \n","79         NaN           64          32                  8.0   \n","80         NaN           64          64                  6.0   \n","81         NaN           64          64                  7.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","77              LOCF  5.41  46.660000  6.83  0.03    -11.90        9.35  \n","78              LOCF  5.41  46.799999  6.84 -0.06    -33.30       10.80  \n","79              LOCF  5.48  48.419998  6.96 -0.20    -40.19       13.56  \n","80              LOCF  5.60  49.490002  7.04 -0.03    -18.40        9.61  \n","81              LOCF  5.97  55.810001  7.47 -0.27    -41.04       12.64  \n","\n","[82 rows x 11 columns]\n","Hidden size:  64\n","Batch_size:  64\n","Window size:  8\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0           64          64                    8              LOCF  5.24   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -40.46  43.830002  6.62 -0.09       12.05  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","78         NaN           64          32                  7.0   \n","79         NaN           64          32                  8.0   \n","80         NaN           64          64                  6.0   \n","81         NaN           64          64                  7.0   \n","82         NaN           64          64                  8.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","78              LOCF  5.41  46.799999  6.84 -0.06    -33.30       10.80  \n","79              LOCF  5.48  48.419998  6.96 -0.20    -40.19       13.56  \n","80              LOCF  5.60  49.490002  7.04 -0.03    -18.40        9.61  \n","81              LOCF  5.97  55.810001  7.47 -0.27    -41.04       12.64  \n","82              LOCF  5.24  43.830002  6.62 -0.09    -40.46       12.05  \n","\n","[83 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  16\n","Window size:  6\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          16                    6              LOCF  5.42   \n","\n","   Accuracy    MSE  RMSE   R2  custom_MSE  \n","0    -13.37  48.16  6.94 -0.0        9.85  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","79         NaN           64          32                  8.0   \n","80         NaN           64          64                  6.0   \n","81         NaN           64          64                  7.0   \n","82         NaN           64          64                  8.0   \n","83         NaN          128          16                  6.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","79              LOCF  5.48  48.419998  6.96 -0.20    -40.19       13.56  \n","80              LOCF  5.60  49.490002  7.04 -0.03    -18.40        9.61  \n","81              LOCF  5.97  55.810001  7.47 -0.27    -41.04       12.64  \n","82              LOCF  5.24  43.830002  6.62 -0.09    -40.46       12.05  \n","83              LOCF  5.42  48.160000  6.94 -0.00    -13.37        9.85  \n","\n","[84 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  16\n","Window size:  7\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          16                    7              LOCF  5.71   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -57.15  49.509998  7.04 -0.12       15.33  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","80         NaN           64          64                  6.0   \n","81         NaN           64          64                  7.0   \n","82         NaN           64          64                  8.0   \n","83         NaN          128          16                  6.0   \n","84         NaN          128          16                  7.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","80              LOCF  5.60  49.490002  7.04 -0.03    -18.40        9.61  \n","81              LOCF  5.97  55.810001  7.47 -0.27    -41.04       12.64  \n","82              LOCF  5.24  43.830002  6.62 -0.09    -40.46       12.05  \n","83              LOCF  5.42  48.160000  6.94 -0.00    -13.37        9.85  \n","84              LOCF  5.71  49.509998  7.04 -0.12    -57.15       15.33  \n","\n","[85 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  16\n","Window size:  8\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          16                    8              LOCF  5.15   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -26.94  42.860001  6.55 -0.06       10.61  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","81         NaN           64          64                  7.0   \n","82         NaN           64          64                  8.0   \n","83         NaN          128          16                  6.0   \n","84         NaN          128          16                  7.0   \n","85         NaN          128          16                  8.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","81              LOCF  5.97  55.810001  7.47 -0.27    -41.04       12.64  \n","82              LOCF  5.24  43.830002  6.62 -0.09    -40.46       12.05  \n","83              LOCF  5.42  48.160000  6.94 -0.00    -13.37        9.85  \n","84              LOCF  5.71  49.509998  7.04 -0.12    -57.15       15.33  \n","85              LOCF  5.15  42.860001  6.55 -0.06    -26.94       10.61  \n","\n","[86 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  32\n","Window size:  6\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          32                    6              LOCF  5.35   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -1.72  48.470001  6.96 -0.01        8.33  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","82         NaN           64          64                  8.0   \n","83         NaN          128          16                  6.0   \n","84         NaN          128          16                  7.0   \n","85         NaN          128          16                  8.0   \n","86         NaN          128          32                  6.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","82              LOCF  5.24  43.830002  6.62 -0.09    -40.46       12.05  \n","83              LOCF  5.42  48.160000  6.94 -0.00    -13.37        9.85  \n","84              LOCF  5.71  49.509998  7.04 -0.12    -57.15       15.33  \n","85              LOCF  5.15  42.860001  6.55 -0.06    -26.94       10.61  \n","86              LOCF  5.35  48.470001  6.96 -0.01     -1.72        8.33  \n","\n","[87 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  32\n","Window size:  7\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          32                    7              LOCF  5.92   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0    -66.48  56.77  7.53 -0.29   17.950001  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","83         NaN          128          16                  6.0   \n","84         NaN          128          16                  7.0   \n","85         NaN          128          16                  8.0   \n","86         NaN          128          32                  6.0   \n","87         NaN          128          32                  7.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35    8.010000  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69    8.530000  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06    9.490000  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95    8.340000  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97   10.210000  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","83              LOCF  5.42  48.160000  6.94 -0.00    -13.37    9.850000  \n","84              LOCF  5.71  49.509998  7.04 -0.12    -57.15   15.330000  \n","85              LOCF  5.15  42.860001  6.55 -0.06    -26.94   10.610000  \n","86              LOCF  5.35  48.470001  6.96 -0.01     -1.72    8.330000  \n","87              LOCF  5.92  56.770000  7.53 -0.29    -66.48   17.950001  \n","\n","[88 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  32\n","Window size:  8\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          32                    8              LOCF  5.37   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -18.47  45.009998  6.71 -0.12        9.43  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","84         NaN          128          16                  7.0   \n","85         NaN          128          16                  8.0   \n","86         NaN          128          32                  6.0   \n","87         NaN          128          32                  7.0   \n","88         NaN          128          32                  8.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35    8.010000  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69    8.530000  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06    9.490000  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95    8.340000  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97   10.210000  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","84              LOCF  5.71  49.509998  7.04 -0.12    -57.15   15.330000  \n","85              LOCF  5.15  42.860001  6.55 -0.06    -26.94   10.610000  \n","86              LOCF  5.35  48.470001  6.96 -0.01     -1.72    8.330000  \n","87              LOCF  5.92  56.770000  7.53 -0.29    -66.48   17.950001  \n","88              LOCF  5.37  45.009998  6.71 -0.12    -18.47    9.430000  \n","\n","[89 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  64\n","Window size:  6\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          64                    6              LOCF  5.81   \n","\n","   Accuracy    MSE  RMSE    R2  custom_MSE  \n","0    -34.84  53.73  7.33 -0.12       12.84  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","85         NaN          128          16                  8.0   \n","86         NaN          128          32                  6.0   \n","87         NaN          128          32                  7.0   \n","88         NaN          128          32                  8.0   \n","89         NaN          128          64                  6.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35    8.010000  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69    8.530000  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06    9.490000  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95    8.340000  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97   10.210000  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","85              LOCF  5.15  42.860001  6.55 -0.06    -26.94   10.610000  \n","86              LOCF  5.35  48.470001  6.96 -0.01     -1.72    8.330000  \n","87              LOCF  5.92  56.770000  7.53 -0.29    -66.48   17.950001  \n","88              LOCF  5.37  45.009998  6.71 -0.12    -18.47    9.430000  \n","89              LOCF  5.81  53.730000  7.33 -0.12    -34.84   12.840000  \n","\n","[90 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  64\n","Window size:  7\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          64                    7              LOCF  5.56   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -21.18  48.209999  6.94 -0.09        9.63  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","86         NaN          128          32                  6.0   \n","87         NaN          128          32                  7.0   \n","88         NaN          128          32                  8.0   \n","89         NaN          128          64                  6.0   \n","90         NaN          128          64                  7.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35    8.010000  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69    8.530000  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06    9.490000  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95    8.340000  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97   10.210000  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","86              LOCF  5.35  48.470001  6.96 -0.01     -1.72    8.330000  \n","87              LOCF  5.92  56.770000  7.53 -0.29    -66.48   17.950001  \n","88              LOCF  5.37  45.009998  6.71 -0.12    -18.47    9.430000  \n","89              LOCF  5.81  53.730000  7.33 -0.12    -34.84   12.840000  \n","90              LOCF  5.56  48.209999  6.94 -0.09    -21.18    9.630000  \n","\n","[91 rows x 11 columns]\n","Hidden size:  128\n","Batch_size:  64\n","Window size:  8\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          128          64                    8              LOCF  5.69   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -45.28  50.990002  7.14 -0.26       13.41  \n","    Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0          NaN           64          16                  0.5   \n","1          NaN           64          16                  0.5   \n","2          NaN           64          16                  1.0   \n","3          NaN           64          16                  1.0   \n","4          NaN           64          16                  2.0   \n","..         ...          ...         ...                  ...   \n","87         NaN          128          32                  7.0   \n","88         NaN          128          32                  8.0   \n","89         NaN          128          64                  6.0   \n","90         NaN          128          64                  7.0   \n","91         NaN          128          64                  8.0   \n","\n","   imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                NaN  7.09  86.710000  9.31 -0.13     10.35    8.010000  \n","1               LOCF  6.71  73.889999  8.60 -0.02      6.69    8.530000  \n","2                NaN  6.47  70.760002  8.41  0.07     -4.06    9.490000  \n","3               LOCF  6.71  73.589996  8.58 -0.05      6.95    8.340000  \n","4                NaN  6.20  65.279999  8.08  0.10     -2.97   10.210000  \n","..               ...   ...        ...   ...   ...       ...         ...  \n","87              LOCF  5.92  56.770000  7.53 -0.29    -66.48   17.950001  \n","88              LOCF  5.37  45.009998  6.71 -0.12    -18.47    9.430000  \n","89              LOCF  5.81  53.730000  7.33 -0.12    -34.84   12.840000  \n","90              LOCF  5.56  48.209999  6.94 -0.09    -21.18    9.630000  \n","91              LOCF  5.69  50.990002  7.14 -0.26    -45.28   13.410000  \n","\n","[92 rows x 11 columns]\n"]}]},{"cell_type":"code","source":["hidden_sizes = [256]\n","batch_sizes = [16, 32, 64]\n","window_sizes = [0.5, 1, 2, 3, 4, 5]\n","imputation_methods = ['None', 'LOCF']\n","\n","hyperparameter_tuning_loop(data_train, hidden_sizes, batch_sizes, window_sizes, imputation_methods,\n","                            results_saving_dir = folder_name,  ifresetresults = False,\n","                            selected_participants_data = selected_participants_data, selected_participants = selected_participants)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":518},"id":"-9OxVGbRq3lo","executionInfo":{"status":"error","timestamp":1693525206936,"user_tz":-60,"elapsed":12515,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"ec8158f9-5519-4eb8-fc1f-9d4d200da3fa"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-4a433ffe0a8b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimputation_methods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'None'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LOCF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m hyperparameter_tuning_loop(data_train, hidden_sizes, batch_sizes, window_sizes, imputation_methods,\n\u001b[0m\u001b[1;32m      7\u001b[0m                             \u001b[0mresults_saving_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder_name\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mifresetresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                             selected_participants_data = selected_participants_data, selected_participants = selected_participants)\n","\u001b[0;32m<ipython-input-19-c76d3b160f87>\u001b[0m in \u001b[0;36mhyperparameter_tuning_loop\u001b[0;34m(mydata, hidden_sizes, batch_sizes, window_sizes, imputation_methods, results_saving_dir, ifresetresults, selected_participants_data, selected_participants)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["hidden_sizes = [256]\n","batch_sizes = [64]\n","window_sizes = [4, 5]\n","imputation_methods = ['None', 'LOCF']\n","\n","hyperparameter_tuning_loop(data_train, hidden_sizes, batch_sizes, window_sizes, imputation_methods,\n","                            results_saving_dir = folder_name,  ifresetresults = False,\n","                            selected_participants_data = selected_participants_data, selected_participants = selected_participants)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N6BzLjby9_5b","executionInfo":{"status":"ok","timestamp":1693526019352,"user_tz":-60,"elapsed":756117,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"2a04ea0c-f82c-4eeb-f92b-ab7933fb319b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hidden size:  256\n","Batch_size:  64\n","Window size:  4\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          256          64                    4              None  5.41   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -10.96  48.389999  6.96  0.24        9.02  \n","     Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0           NaN           64          16                  0.5   \n","1           NaN           64          16                  0.5   \n","2           NaN           64          16                  1.0   \n","3           NaN           64          16                  1.0   \n","4           NaN           64          16                  2.0   \n","..          ...          ...         ...                  ...   \n","121         NaN          256          64                  2.0   \n","122         NaN          256          64                  3.0   \n","123         NaN          256          64                  3.0   \n","124         NaN          256          64                  4.0   \n","125         NaN          256          64                  4.0   \n","\n","    imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                 NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1                LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                 NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3                LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                 NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..                ...   ...        ...   ...   ...       ...         ...  \n","121              LOCF  6.73  75.900002  8.71 -0.16     10.46        8.84  \n","122               NaN  6.08  57.900002  7.61  0.14    -13.03       10.24  \n","123              LOCF  6.28  64.919998  8.06 -0.07      0.05        9.94  \n","124               NaN  6.33  64.599998  8.04 -0.01    -21.30       12.12  \n","125              None  5.41  48.389999  6.96  0.24    -10.96        9.02  \n","\n","[126 rows x 11 columns]\n","Hidden size:  256\n","Batch_size:  64\n","Window size:  4\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          256          64                    4              LOCF  5.81   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      2.31  54.650002  7.39  0.03        8.05  \n","     Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0           NaN           64          16                  0.5   \n","1           NaN           64          16                  0.5   \n","2           NaN           64          16                  1.0   \n","3           NaN           64          16                  1.0   \n","4           NaN           64          16                  2.0   \n","..          ...          ...         ...                  ...   \n","122         NaN          256          64                  3.0   \n","123         NaN          256          64                  3.0   \n","124         NaN          256          64                  4.0   \n","125         NaN          256          64                  4.0   \n","126         NaN          256          64                  4.0   \n","\n","    imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                 NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1                LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                 NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3                LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                 NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..                ...   ...        ...   ...   ...       ...         ...  \n","122               NaN  6.08  57.900002  7.61  0.14    -13.03       10.24  \n","123              LOCF  6.28  64.919998  8.06 -0.07      0.05        9.94  \n","124               NaN  6.33  64.599998  8.04 -0.01    -21.30       12.12  \n","125               NaN  5.41  48.389999  6.96  0.24    -10.96        9.02  \n","126              LOCF  5.81  54.650002  7.39  0.03      2.31        8.05  \n","\n","[127 rows x 11 columns]\n","Hidden size:  256\n","Batch_size:  64\n","Window size:  5\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          256          64                    5              None  5.01   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      0.88  38.740002  6.22  0.36        6.05  \n","     Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0           NaN           64          16                  0.5   \n","1           NaN           64          16                  0.5   \n","2           NaN           64          16                  1.0   \n","3           NaN           64          16                  1.0   \n","4           NaN           64          16                  2.0   \n","..          ...          ...         ...                  ...   \n","123         NaN          256          64                  3.0   \n","124         NaN          256          64                  4.0   \n","125         NaN          256          64                  4.0   \n","126         NaN          256          64                  4.0   \n","127         NaN          256          64                  5.0   \n","\n","    imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                 NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1                LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                 NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3                LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                 NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..                ...   ...        ...   ...   ...       ...         ...  \n","123              LOCF  6.28  64.919998  8.06 -0.07      0.05        9.94  \n","124               NaN  6.33  64.599998  8.04 -0.01    -21.30       12.12  \n","125               NaN  5.41  48.389999  6.96  0.24    -10.96        9.02  \n","126              LOCF  5.81  54.650002  7.39  0.03      2.31        8.05  \n","127              None  5.01  38.740002  6.22  0.36      0.88        6.05  \n","\n","[128 rows x 11 columns]\n","Hidden size:  256\n","Batch_size:  64\n","Window size:  5\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          256          64                    5              LOCF  5.66   \n","\n","   Accuracy    MSE  RMSE   R2  custom_MSE  \n","0     -21.4  51.84   7.2  0.0       10.78  \n","     Unnamed: 0  hidden_size  batch_size  sliding_window_size  \\\n","0           NaN           64          16                  0.5   \n","1           NaN           64          16                  0.5   \n","2           NaN           64          16                  1.0   \n","3           NaN           64          16                  1.0   \n","4           NaN           64          16                  2.0   \n","..          ...          ...         ...                  ...   \n","124         NaN          256          64                  4.0   \n","125         NaN          256          64                  4.0   \n","126         NaN          256          64                  4.0   \n","127         NaN          256          64                  5.0   \n","128         NaN          256          64                  5.0   \n","\n","    imputation_method   MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0                 NaN  7.09  86.710000  9.31 -0.13     10.35        8.01  \n","1                LOCF  6.71  73.889999  8.60 -0.02      6.69        8.53  \n","2                 NaN  6.47  70.760002  8.41  0.07     -4.06        9.49  \n","3                LOCF  6.71  73.589996  8.58 -0.05      6.95        8.34  \n","4                 NaN  6.20  65.279999  8.08  0.10     -2.97       10.21  \n","..                ...   ...        ...   ...   ...       ...         ...  \n","124               NaN  6.33  64.599998  8.04 -0.01    -21.30       12.12  \n","125               NaN  5.41  48.389999  6.96  0.24    -10.96        9.02  \n","126              LOCF  5.81  54.650002  7.39  0.03      2.31        8.05  \n","127               NaN  5.01  38.740002  6.22  0.36      0.88        6.05  \n","128              LOCF  5.66  51.840000  7.20  0.00    -21.40       10.78  \n","\n","[129 rows x 11 columns]\n"]}]},{"cell_type":"markdown","source":["## Select best hyperparameters\n"],"metadata":{"id":"hzo9rdE7Bh49"}},{"cell_type":"code","source":["folder_name = '/content/drive/MyDrive/sleep onset datasets/FIXED_regression_LSTM_perfectly_clean_onset'\n","results_df_all = pd.read_csv(folder_name + '/results.csv')\n","\n","\n","\n","# swap all NaNs in imputation_method' with 'None'\n","results_df_all['imputation_method'] = results_df_all['imputation_method'].fillna('None')\n","\n","# drop Unnamed: 0 column\n","results_df_all = results_df_all.drop(columns=['Unnamed: 0'])\n","\n","\n","# group results by LOCF and None and for each method find the lowest custmo MSE in a for loop\n","\n","for method, results_method in results_df_all.groupby('imputation_method'):\n","    print(method)\n","    sorted_results = results_method.sort_values(by=['custom_MSE'])\n","    print(sorted_results.head(5))\n","    # Save the results as a latex table (without the index column)\n","    # drop the imputation method and Accuracy columns\n","    sorted_results = sorted_results.drop(columns=['imputation_method', 'Accuracy'])\n","\n","    # put the custom MSE column after sliding_window_size\n","    cols = sorted_results.columns.tolist()\n","    cols = cols[:3] + cols[-1:] + cols[3:-1]\n","    sorted_results = sorted_results[cols]\n","\n","    # Rename the columns: Hidden size, Batch size, Window size (min), Custom MSE, MAE, MSE, RMSE, R2\n","\n","\n","    headers = ['Hidden size', 'Batch size', 'Window size (min)', 'Custom MSE', 'MAE', 'MSE', 'RMSE', 'R2']\n","    sorted_results.columns = headers\n","\n","    # Save only the top 3 results\n","    sorted_results = sorted_results.head(5)\n","\n","    # make the values in the table only have 2 decimal places after saving\n","    sorted_results = sorted_results.round(2)\n","\n","    print(sorted_results)\n","\n","    sorted_results.to_latex(folder_name + f'/results_top5_{method}.tex', index=False, float_format=\"%.2f\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RHZY8h3NuWd7","executionInfo":{"status":"ok","timestamp":1693571620583,"user_tz":-60,"elapsed":2469,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"d5238898-783a-4278-c36f-52c89a1439e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LOCF\n","     hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","111          256          32                  3.0              LOCF  5.93   \n","5             64          16                  2.0              LOCF  6.81   \n","74            64          16                  6.0              LOCF  5.59   \n","7             64          16                  3.0              LOCF  5.79   \n","34            64          64                  4.0              LOCF  5.91   \n","\n","           MSE  RMSE    R2  Accuracy  custom_MSE  \n","111  59.009998  7.68  0.03     16.97        6.38  \n","5    81.230003  9.01 -0.24     20.68        6.65  \n","74   51.849998  7.20 -0.08      2.53        6.98  \n","7    55.110001  7.42  0.09     12.13        7.00  \n","34   57.230000  7.56 -0.02     12.79        7.07  \n","     Hidden size  Batch size  Window size (min)  Custom MSE   MAE    MSE  \\\n","111          256          32                3.0        6.38  5.93  59.01   \n","5             64          16                2.0        6.65  6.81  81.23   \n","74            64          16                6.0        6.98  5.59  51.85   \n","7             64          16                3.0        7.00  5.79  55.11   \n","34            64          64                4.0        7.07  5.91  57.23   \n","\n","     RMSE    R2  \n","111  7.68  0.03  \n","5    9.01 -0.24  \n","74   7.20 -0.08  \n","7    7.42  0.09  \n","34   7.56 -0.02  \n","None\n","     hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","114          256          32                  5.0              None  4.66   \n","98           256          16                  3.0              None  5.29   \n","110          256          32                  3.0              None  5.48   \n","127          256          64                  5.0              None  5.01   \n","112          256          32                  4.0              None  4.73   \n","\n","           MSE  RMSE    R2  Accuracy  custom_MSE  \n","114  33.500000  5.79  0.45      9.67        4.94  \n","98   48.040001  6.93  0.28     25.37        5.26  \n","110  50.709999  7.12  0.24     21.60        5.70  \n","127  38.740002  6.22  0.36      0.88        6.05  \n","112  37.880001  6.15  0.41     10.99        6.05  \n","     Hidden size  Batch size  Window size (min)  Custom MSE   MAE    MSE  \\\n","114          256          32                5.0        4.94  4.66  33.50   \n","98           256          16                3.0        5.26  5.29  48.04   \n","110          256          32                3.0        5.70  5.48  50.71   \n","127          256          64                5.0        6.05  5.01  38.74   \n","112          256          32                4.0        6.05  4.73  37.88   \n","\n","     RMSE    R2  \n","114  5.79  0.45  \n","98   6.93  0.28  \n","110  7.12  0.24  \n","127  6.22  0.36  \n","112  6.15  0.41  \n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-21-30da5c5d8f71>:42: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n","  sorted_results.to_latex(folder_name + f'/results_top5_{method}.tex', index=False, float_format=\"%.2f\")\n","<ipython-input-21-30da5c5d8f71>:42: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n","  sorted_results.to_latex(folder_name + f'/results_top5_{method}.tex', index=False, float_format=\"%.2f\")\n"]}]},{"cell_type":"markdown","source":["## Test the best model\n"],"metadata":{"id":"u2hSmB73BDS5"}},{"cell_type":"code","source":["hidden_sizes = [256]\n","batch_sizes = [32]\n","window_sizes = [5]\n","imputation_methods = ['None']\n","folder_name = '/content/drive/MyDrive/sleep onset datasets/FIXED_regression_LSTM_perfectly_clean_onset/test_best_models'\n","hyperparameter_tuning_loop(data_train, hidden_sizes, batch_sizes, window_sizes, imputation_methods,\n","                            results_saving_dir = folder_name,  ifresetresults = True,\n","                            selected_participants_data = selected_participants_data, selected_participants = selected_participants, test_data = data_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UVkbvADKBIn9","executionInfo":{"status":"ok","timestamp":1693929330550,"user_tz":-60,"elapsed":117059,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"82db38d5-d6f2-4c28-fcb0-6d073120d00f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hidden size:  256\n","Batch_size:  32\n","Window size:  5\n","Imputation method:  None\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          256          32                    5              None  6.65   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0     -81.4  67.620003  8.22 -0.09       15.24  \n","  Unnamed: 0 hidden_size batch_size sliding_window_size imputation_method  \\\n","0        NaN         256         32                   5              None   \n","\n","    MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0  6.65  67.620003  8.22 -0.09     -81.4       15.24  \n"]}]},{"cell_type":"code","source":["hidden_sizes = [256]\n","batch_sizes = [32]\n","window_sizes = [3]\n","imputation_methods = ['LOCF']\n","folder_name = '/content/drive/MyDrive/sleep onset datasets/FIXED_regression_LSTM_perfectly_clean_onset/test_best_models'\n","hyperparameter_tuning_loop(data_train, hidden_sizes, batch_sizes, window_sizes, imputation_methods,\n","                            results_saving_dir = folder_name,  ifresetresults = False,\n","                            selected_participants_data = selected_participants_data, selected_participants = selected_participants, test_data = data_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AcU9T_NvBCew","executionInfo":{"status":"ok","timestamp":1693929703836,"user_tz":-60,"elapsed":338976,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"0fec1614-33bf-47b4-c778-72e71cff12b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hidden size:  256\n","Batch_size:  32\n","Window size:  3\n","Imputation method:  LOCF\n","Epoch 1/30\n","Epoch 2/30\n","Epoch 3/30\n","Epoch 4/30\n","Epoch 5/30\n","Epoch 6/30\n","Epoch 7/30\n","Epoch 8/30\n","Epoch 9/30\n","Epoch 10/30\n","Epoch 11/30\n","Epoch 12/30\n","Epoch 13/30\n","Epoch 14/30\n","Epoch 15/30\n","Epoch 16/30\n","Epoch 17/30\n","Epoch 18/30\n","Epoch 19/30\n","Epoch 20/30\n","Epoch 21/30\n","Epoch 22/30\n","Epoch 23/30\n","Epoch 24/30\n","Epoch 25/30\n","Epoch 26/30\n","Epoch 27/30\n","Epoch 28/30\n","Epoch 29/30\n","Epoch 30/30\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          256          32                    3              LOCF  6.66   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -24.14  71.669998  8.47 -0.18       14.45  \n","   Unnamed: 0  hidden_size  batch_size  sliding_window_size imputation_method  \\\n","0         NaN          256          32                    5               NaN   \n","1         NaN          256          32                    3              LOCF   \n","\n","    MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0  6.65  67.620000  8.22 -0.09    -81.40       15.24  \n","1  6.66  71.669998  8.47 -0.18    -24.14       14.45  \n"]}]},{"cell_type":"code","source":["data_test.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zTjQpTu-J9sY","executionInfo":{"status":"ok","timestamp":1693931014578,"user_tz":-60,"elapsed":4,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"ec652c64-3a2e-4919-da45-65df7e7e9c29"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Label', 'Sbj_ID', 'Age', 'Gender', 'Race1', 'Race2', 'Race3', 'Race4',\n","       'ifCleanOnset', 'Time2Sleep', 'SleepStage', 'delta', 'theta', 'alpha',\n","       'beta', 'DTratio', 'DAratio', 'DBratio', 'TAratio', 'TBratio',\n","       'ABratio', 'Transratio', 'deltapeak', 'thetapeak', 'alphapeak',\n","       'betapeak', 'TCdelta', 'TCtheta', 'TCalpha', 'TCbeta',\n","       'DN_HistogramMode_5', 'DN_HistogramMode_10', 'CO_f1ecac',\n","       'CO_FirstMin_ac', 'CO_HistogramAMI_even_2_5', 'CO_trev_1_num',\n","       'MD_hrv_classic_pnn40', 'SB_BinaryStats_mean_longstretch1',\n","       'SB_TransitionMatrix_3ac_sumdiagcov', 'PD_PeriodicityWang_th0_01',\n","       'CO_Embed2_Dist_tau_d_expfit_meandiff',\n","       'IN_AutoMutualInfoStats_40_gaussian_fmmi',\n","       'FC_LocalSimple_mean1_tauresrat', 'DN_OutlierInclude_p_001_mdrmd',\n","       'DN_OutlierInclude_n_001_mdrmd', 'SP_Summaries_welch_rect_area_5_1',\n","       'SB_BinaryStats_diff_longstretch0', 'SB_MotifThree_quantile_hh',\n","       'SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1',\n","       'SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1',\n","       'SP_Summaries_welch_rect_centroid', 'FC_LocalSimple_mean3_stderr',\n","       'gamma', 'GAration', 'GBratio', 'GTratio', 'GDratio', 'gammapeak',\n","       'TCgamma', 'DTcouple', 'DAcouple', 'DBcouple', 'TAcouple', 'TBcouple',\n","       'ABcouple', 'DGcouple', 'TGcouple', 'AGcouple', 'BGcouple',\n","       'Entropy Rate LZ', 'Aperiodic component (spectral exponent)',\n","       'O-information', 'S-information', 'nap5', 'trbleslpng5', 'slpngpills5',\n","       'sleepy5', 'legsdscmfrt5', 'rubbnglgs5', 'wrserest5', 'wrseltr5',\n","       'slpapnea5', 'cpap5', 'dntaldv5', 'uvula5', 'insmnia5', 'rstlesslgs5',\n","       'whiirs5c', 'epslpscl5c', 'hoostmeq5c'],\n","      dtype='object')"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["def extract_models_from_folder(folder_name,  hidden_size, batch_size, sliding_window_sizes, imputation_method):\n","    model_dir = folder_name + '/' + f'hidden_{hidden_size}_batch_{batch_size}_window_{sliding_window_sizes}_imputation_{imputation_method}'\n","    model_name = f'model_h{hidden_size}_b{batch_size}_w{sliding_window_sizes}_{imputation_method}.pt'\n","    model_dict = torch.load(model_dir + '/' + model_name)\n","    model = SleepOnsetRNNRegressor(input_size=86, hidden_size=hidden_size, num_layers=2).to(device)\n","    model.load_state_dict(model_dict)\n","    return model\n"],"metadata":{"id":"zDwHA-54HNNj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hidden_sizes = [256]\n","batch_sizes = [32]\n","window_sizes = [5]\n","imputation_methods = ['None']\n","folder_name = '/content/drive/MyDrive/sleep onset datasets/FIXED_regression_LSTM_perfectly_clean_onset/test_best_models_from_pretrained'\n","extraction_name = '/content/drive/MyDrive/sleep onset datasets/FIXED_regression_LSTM_perfectly_clean_onset'\n","hyperparameter_tuning_loop(data_train, hidden_sizes, batch_sizes, window_sizes, imputation_methods,\n","                            results_saving_dir = folder_name,  ifresetresults = True,\n","                            test_data = data_test,\n","                           if_pretrained_model = True, extraction_name = extraction_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CLZbNVUgIi0H","executionInfo":{"status":"ok","timestamp":1693931845299,"user_tz":-60,"elapsed":38160,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"509fa492-e209-4ffa-c86b-bbb131904b09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hidden size:  256\n","Batch_size:  32\n","Window size:  5\n","Imputation method:  None\n","Skipping participant 460 due to lack of data.\n","Skipping participant 893 due to lack of data.\n","Skipping participant 1033 due to lack of data.\n","Skipping participant 1501 due to lack of data.\n","Skipping participant 2413 due to lack of data.\n","Skipping participant 3641 due to lack of data.\n","Skipping participant 3793 due to lack of data.\n","Skipping participant 3894 due to lack of data.\n","Skipping participant 4806 due to lack of data.\n","Skipping participant 5438 due to lack of data.\n","Skipping participant 5476 due to lack of data.\n","Skipping participant 5722 due to lack of data.\n","Skipping participant 5784 due to lack of data.\n","Skipping participant 6629 due to lack of data.\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          256          32                    5              None  5.74   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0    -47.26  51.779999   7.2  0.17       10.62  \n","  Unnamed: 0 hidden_size batch_size sliding_window_size imputation_method  \\\n","0        NaN         256         32                   5              None   \n","\n","    MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0  5.74  51.779999   7.2  0.17    -47.26       10.62  \n"]}]},{"cell_type":"code","source":["hidden_sizes = [256]\n","batch_sizes = [32]\n","window_sizes = [3]\n","imputation_methods = ['LOCF']\n","folder_name = '/content/drive/MyDrive/sleep onset datasets/FIXED_regression_LSTM_perfectly_clean_onset/test_best_models_from_pretrained'\n","extraction_name = '/content/drive/MyDrive/sleep onset datasets/FIXED_regression_LSTM_perfectly_clean_onset'\n","hyperparameter_tuning_loop(data_train, hidden_sizes, batch_sizes, window_sizes, imputation_methods,\n","                            results_saving_dir = folder_name,  ifresetresults = False,\n","                            test_data = data_test,\n","                           if_pretrained_model = True, extraction_name = extraction_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OXOMM2aVIxbD","executionInfo":{"status":"ok","timestamp":1693931912698,"user_tz":-60,"elapsed":67400,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"840b06d5-dcea-40ac-b2ba-31b4b158961a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hidden size:  256\n","Batch_size:  32\n","Window size:  3\n","Imputation method:  LOCF\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          256          32                    3              LOCF  6.62   \n","\n","   Accuracy        MSE  RMSE    R2  custom_MSE  \n","0      3.41  73.239998  8.56 -0.21        9.53  \n","   Unnamed: 0  hidden_size  batch_size  sliding_window_size imputation_method  \\\n","0         NaN          256          32                    5               NaN   \n","1         NaN          256          32                    3              LOCF   \n","\n","    MAE        MSE  RMSE    R2  Accuracy  custom_MSE  \n","0  5.74  51.780000  7.20  0.17    -47.26       10.62  \n","1  6.62  73.239998  8.56 -0.21      3.41        9.53  \n"]}]},{"cell_type":"code","source":["folder_name = '/content/drive/MyDrive/sleep onset datasets/FIXED_regression_LSTM_perfectly_clean_onset/test_best_models_from_pretrained'\n","results_df_all = pd.read_csv(folder_name + '/results.csv')\n","\n","\n","\n","# swap all NaNs in imputation_method' with 'None'\n","results_df_all['imputation_method'] = results_df_all['imputation_method'].fillna('None')\n","\n","# drop Unnamed: 0 column\n","results_df_all = results_df_all.drop(columns=['Unnamed: 0'])\n","\n","\n","# group results by LOCF and None and for each method find the lowest custmo MSE in a for loop\n","\n","for method, results_method in results_df_all.groupby('imputation_method'):\n","    print(method)\n","    sorted_results = results_method.sort_values(by=['custom_MSE'])\n","    print(sorted_results.head(5))\n","    # Save the results as a latex table (without the index column)\n","    # drop the imputation method and Accuracy columns\n","    sorted_results = sorted_results.drop(columns=['imputation_method', 'Accuracy'])\n","\n","    # put the custom MSE column after sliding_window_size\n","    cols = sorted_results.columns.tolist()\n","    cols = cols[:3] + cols[-1:] + cols[3:-1]\n","    sorted_results = sorted_results[cols]\n","\n","    # Rename the columns: Hidden size, Batch size, Window size (min), Custom MSE, MAE, MSE, RMSE, R2\n","\n","\n","    headers = ['Hidden size', 'Batch size', 'Window size (min)', 'Custom MSE', 'MAE', 'MSE', 'RMSE', 'R2']\n","    sorted_results.columns = headers\n","\n","    # Save only the top 3 results\n","    sorted_results = sorted_results.head(5)\n","\n","    # make the values in the table only have 2 decimal places after saving\n","    sorted_results = sorted_results.round(2)\n","\n","    print(sorted_results)\n","\n","    sorted_results.to_latex(folder_name + f'/results_top5_{method}.tex', index=False, float_format=\"%.2f\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2eobmeGyRvzV","executionInfo":{"status":"ok","timestamp":1693933080564,"user_tz":-60,"elapsed":1303,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"cd0ecc16-60b6-48fd-d73f-8fc3f16ce167"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LOCF\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","1          256          32                    3              LOCF  6.62   \n","\n","         MSE  RMSE    R2  Accuracy  custom_MSE  \n","1  73.239998  8.56 -0.21      3.41        9.53  \n","   Hidden size  Batch size  Window size (min)  Custom MSE   MAE    MSE  RMSE  \\\n","1          256          32                  3        9.53  6.62  73.24  8.56   \n","\n","     R2  \n","1 -0.21  \n","None\n","   hidden_size  batch_size  sliding_window_size imputation_method   MAE  \\\n","0          256          32                    5              None  5.74   \n","\n","     MSE  RMSE    R2  Accuracy  custom_MSE  \n","0  51.78   7.2  0.17    -47.26       10.62  \n","   Hidden size  Batch size  Window size (min)  Custom MSE   MAE    MSE  RMSE  \\\n","0          256          32                  5       10.62  5.74  51.78   7.2   \n","\n","     R2  \n","0  0.17  \n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-50-4c43e275a5e9>:42: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n","  sorted_results.to_latex(folder_name + f'/results_top5_{method}.tex', index=False, float_format=\"%.2f\")\n","<ipython-input-50-4c43e275a5e9>:42: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n","  sorted_results.to_latex(folder_name + f'/results_top5_{method}.tex', index=False, float_format=\"%.2f\")\n"]}]},{"cell_type":"markdown","source":["## plot histrogram of custom MSE for all models"],"metadata":{"id":"jx-R0Ih7wGuJ"}},{"cell_type":"code","source":[" folder_name = '/content/drive/MyDrive/sleep onset datasets/FIXED_regression_LSTM_perfectly_clean_onset/test_best_models_from_pretrained'\n","\n"," hidden_size = 256\n"," batch_size = 32\n"," window_size_minutes = 3\n"," imputation_method = 'LOCF'\n","\n","results_dir = os.path.join(folder_name, f'hidden_{hidden_size}_batch_{batch_size}_window_{window_size_minutes}_imputation_{imputation_method}/random_participants')\n","reg_results_LOCF = pd.read_csv(results_dir + '/regression_results_random_participants.csv')\n","\n","# plot a histogram of 'custom_M\n","reg_results_LOCF['custom_MSE'].hist(bins=50)\n","# set xticks to have a step of 5\n","xmin, xmax = plt.xlim()\n","plt.xticks(range(0, int(xmax)+1, 5))\n","\n","# Increase font sizes\n","plt.xlabel('Custom MSE', fontsize=14)\n","plt.ylabel('Number of participants', fontsize=14)\n","plt.xticks(fontsize=12)\n","plt.yticks(fontsize=12)\n","\n","# set figure size\n","plt.gcf().set_size_inches(6, 4)\n","\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"ngB5oKQ4t6Vg","executionInfo":{"status":"ok","timestamp":1694343860811,"user_tz":-60,"elapsed":648,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"d292223a-4198-4f6f-dfd2-6ee447bb1def"},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 600x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[" folder_name = '/content/drive/MyDrive/sleep onset datasets/FIXED_regression_LSTM_clean_onset/test_best_models_from_pretrained'\n","\n"," hidden_size = 64\n"," batch_size = 64\n"," window_size_minutes = 3\n"," imputation_method = 'LOCF'\n","\n","results_dir = os.path.join(folder_name, f'hidden_{hidden_size}_batch_{batch_size}_window_{window_size_minutes}_imputation_{imputation_method}/random_participants')\n","reg_results_LOCF = pd.read_csv(results_dir + '/regression_results_random_participants.csv')\n","\n","# plot a histogram of 'custom_M\n","reg_results_LOCF['custom_MSE'].hist(bins=50)\n","# set xticks to have a step of 5\n","#xmin, xmax = plt.xlim()\n","plt.xticks(range(0, int(xmax)+1, 5))\n","\n","# Increase font sizes\n","plt.xlabel('Custom MSE', fontsize=14)\n","plt.ylabel('Number of participants', fontsize=14)\n","plt.xticks(fontsize=12)\n","plt.yticks(fontsize=12)\n","\n","# set figure size\n","plt.gcf().set_size_inches(6, 4)\n","\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"5ficwTDRwmj8","executionInfo":{"status":"ok","timestamp":1694343861841,"user_tz":-60,"elapsed":380,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"9fa1608a-951e-404e-961d-7080eef9fd5b"},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 600x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[" folder_name = '/content/drive/MyDrive/sleep onset datasets/FIXED_regression_LSTM_perfectly_clean_onset/test_best_models_from_pretrained'\n","\n"," hidden_size = 256\n"," batch_size = 32\n"," window_size_minutes = 5\n"," imputation_method = 'None'\n","\n","results_dir = os.path.join(folder_name, f'hidden_{hidden_size}_batch_{batch_size}_window_{window_size_minutes}_imputation_{imputation_method}/random_participants')\n","reg_results_None= pd.read_csv(results_dir + '/regression_results_random_participants.csv')\n","\n","# plot a histogram of 'custom_M\n","reg_results_None['custom_MSE'].hist(bins=50)\n","# set xticks to have a step of 5\n","xmin, xmax = plt.xlim()\n","plt.xticks(range(0, int(xmax)+1, 5))\n","\n","# Increase font sizes\n","plt.xlabel('Custom MSE', fontsize=14)\n","plt.ylabel('Number of participants', fontsize=14)\n","plt.xticks(fontsize=12)\n","plt.yticks(fontsize=12)\n","\n","# set figure size\n","plt.gcf().set_size_inches(6, 4)\n","\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"OhK19JjKwZj5","executionInfo":{"status":"ok","timestamp":1694343749521,"user_tz":-60,"elapsed":1298,"user":{"displayName":"Anastasia Ilina","userId":"11612942880361505799"}},"outputId":"2a2e7b77-80af-4f6f-8e9a-45f3b1bdf863"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 600x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"myenv","language":"python","name":"myenv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"orig_nbformat":4,"colab":{"provenance":[],"collapsed_sections":["3C1xC_QFV7x1","bvHePGDBWQ89","v7p1LKs4Waq7"],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}